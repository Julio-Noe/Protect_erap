,line #,sentence,Annotator,Named entity,URL
0,3,11.2	Technology description,Data protection,technology,https://w3id.org/dpv#Technology
0,4,"Personal voice assistants – also referred to as digital assistants, AI virtual assistants, intelligent assistants, and so on – are software systems that can provide services to an individual user on the basis of a conversational user interface.",AI Act,user,http://tair.adaptcentre.ie/ontologies/tair/User
0,4,"Personal voice assistants – also referred to as digital assistants, AI virtual assistants, intelligent assistants, and so on – are software systems that can provide services to an individual user on the basis of a conversational user interface.",AI Act,user,http://tair.adaptcentre.ie/ontologies/tair/User
0,4,The conversational user interface that characterizes personal voice assistants entails that the assistant can recognize and understand users’ spoken commands and in turn responds to users in spoken word.,AI Act,user,http://tair.adaptcentre.ie/ontologies/tair/User
0,4,"Personal voice assistants – also referred to as digital assistants, AI virtual assistants, intelligent assistants, and so on – are software systems that can provide services to an individual user on the basis of a conversational user interface.",Data protection,user,https://w3id.org/dpv#User
0,4,"Personal voice assistants – also referred to as digital assistants, AI virtual assistants, intelligent assistants, and so on – are software systems that can provide services to an individual user on the basis of a conversational user interface.",Data protection,user,https://w3id.org/dpv#User
0,4,The conversational user interface that characterizes personal voice assistants entails that the assistant can recognize and understand users’ spoken commands and in turn responds to users in spoken word.,Data protection,user,https://w3id.org/dpv#User
0,4,"This is possible due to natural language processing (NLP), a subfield of artificial intelligence (AI).",Data protection,processing,https://w3id.org/dpv#Processing
0,6,"For example, Amazon’s Alexa can interact with users, play music, make to do lists, set alarms, stream podcasts, play audiobooks, provide information (weather, traffic, news, etc.",Ethics,play,http://eaontology.linkeddata.es/def/Play
0,6,"For example, Amazon’s Alexa can interact with users, play music, make to do lists, set alarms, stream podcasts, play audiobooks, provide information (weather, traffic, news, etc.",Ethics,play,http://eaontology.linkeddata.es/def/Play
0,8,"Voice assistants are personal in that are specifically designed to resemble a human personal assistant and to feel personal to a user, in the sense that the assistant is always there for you, always ready to help you.",AI Act,user,http://tair.adaptcentre.ie/ontologies/tair/User
0,8,"Voice assistants are personal in that are specifically designed to resemble a human personal assistant and to feel personal to a user, in the sense that the assistant is always there for you, always ready to help you.",Data protection,user,https://w3id.org/dpv#User
0,8,"The design of personal voice assistance most commonly exists in a female voice and name, sophisticated use of language, and an extrovert, caring and servile personality.",Data protection,use,https://w3id.org/dpv#Use
0,10,11.3	Context,Data protection,context,https://w3id.org/dpv#Context
0,11,"Today, personal voice assistants are mainly used in the context of one’s private life and private home.",Ethics,life,http://eaontology.linkeddata.es/def/Life
0,11,"Today, personal voice assistants are mainly used in the context of one’s private life and private home.",Data protection,context,https://w3id.org/dpv#Context
0,11,"Personal voice assistants could also be used in a professional context (Finnegan, 2020; Prist, 2018) and for customer service online, via phone call, or even in a physical store, restaurant, or other type of facility.",Data protection,context,https://w3id.org/dpv#Context
0,11,"Personal voice assistants could also be used in a professional context (Finnegan, 2020; Prist, 2018) and for customer service online, via phone call, or even in a physical store, restaurant, or other type of facility.",Data protection,prist,https://w3id.org/dpv#Prist
0,11,"Personal voice assistants could also be used in a professional context (Finnegan, 2020; Prist, 2018) and for customer service online, via phone call, or even in a physical store, restaurant, or other type of facility.",Data protection,customer,https://w3id.org/dpv#Customer
0,11,"Personal voice assistants could also be used in a professional context (Finnegan, 2020; Prist, 2018) and for customer service online, via phone call, or even in a physical store, restaurant, or other type of facility.",Data protection,store,https://w3id.org/dpv#Store
0,11,"In this case study, however, personal voice assistants are studied only in the private context described above.",Data protection,context,https://w3id.org/dpv#Context
0,13,11.3.1	Potential use,Data protection,use,https://w3id.org/dpv#Use
0,14,"Another possible development is that personal voice assistants become connected to wearables, making it possible to get to know a user and his/her routines, health conditions, and emotions even better and adjust services accordingly.",AI Act,user,http://tair.adaptcentre.ie/ontologies/tair/User
0,14,"Currently in the making are for example personal voice assistants that can recognize and respond to human emotions (Day, 2019; Johnson, 2019) or adapt their services to different users of a single device (Amazon Alexa, n.d.).",Data protection,adapt,https://w3id.org/dpv#Adapt
0,14,"Another possible development is that personal voice assistants become connected to wearables, making it possible to get to know a user and his/her routines, health conditions, and emotions even better and adjust services accordingly.",Data protection,user,https://w3id.org/dpv#User
0,16,"recommending certain songs, ordering products, filtering news), by analysing and remembering user’s preferences (e.g.",AI Act,user,http://tair.adaptcentre.ie/ontologies/tair/User
0,16,"music taste, previous purchases, interest in certain news items) and also by recognizing a user’s voice (e.g.",AI Act,user,http://tair.adaptcentre.ie/ontologies/tair/User
0,16,Voice assistants are a personalised technology because they can offer personalised services (e.g.,Data protection,technology,https://w3id.org/dpv#Technology
0,16,"recommending certain songs, ordering products, filtering news), by analysing and remembering user’s preferences (e.g.",Data protection,user,https://w3id.org/dpv#User
0,16,"music taste, previous purchases, interest in certain news items) and also by recognizing a user’s voice (e.g.",Data protection,user,https://w3id.org/dpv#User
0,16,in cases where multiple residents use a single smart speaker).,Data protection,use,https://w3id.org/dpv#Use
0,21,"Below I discuss the found ethical and legal issues, after which I conclude with a few words on possible beneficial aspects of the technology.",Data protection,technology,https://w3id.org/dpv#Technology
0,24,"A first, and obvious, set of concerns has to do with privacy and data-governance, which are both ethical and legal issues.",Ethics,privacy,http://eaontology.linkeddata.es/def/Privacy
0,24,"Voice assistants threaten privacy because at times they record audio data without the user actively using the system or being aware of the fact that the system is recording (Chung et al., 2017; Green, 2018; Temkin & Dorsett, 2019).",Ethics,privacy,http://eaontology.linkeddata.es/def/Privacy
0,24,"rightfully ask “should one expect privacy in the communications he engages in around a voice-controlled digital assistant?” (Boughman et al., 2017, p. 1).",Ethics,privacy,http://eaontology.linkeddata.es/def/Privacy
0,24,"Moreover, privacy is at risk because of the sensitive information that speech could reveal (Cox, 2019).",Ethics,privacy,http://eaontology.linkeddata.es/def/Privacy
0,24,"A first, and obvious, set of concerns has to do with privacy and data-governance, which are both ethical and legal issues.",Data protection,data,https://w3id.org/dpv#Data
0,24,"Moreover, privacy is at risk because of the sensitive information that speech could reveal (Cox, 2019).",Data protection,risk,https://w3id.org/dpv#Risk
0,24,Voice data reveals information that mere text could not (e.g.,Data protection,data,https://w3id.org/dpv#Data
0,24,"In that sense, voice data might be “more private” than other types of personal data (Boughman et al., 2017).",Data protection,data,https://w3id.org/dpv#Data
0,24,"A further issue is the fact that the data and information received by voice assistants can be used by third parties, for example to send personalised advertisements.",Data protection,data,https://w3id.org/dpv#Data
0,24,Green (2018) points out that voice assistants make it easier for third parties to obtain information about individuals and Davis (2016) moots that personal voice assistants might be giving companies too much access to people’s lives.,Data protection,obtain,https://w3id.org/dpv#Obtain
0,24,Green (2018) points out that voice assistants make it easier for third parties to obtain information about individuals and Davis (2016) moots that personal voice assistants might be giving companies too much access to people’s lives.,Data protection,access,https://w3id.org/dpv#Access
0,26,"Despite the various worries raised by specialists, ethicists, legal experts and journalists, studies have shown that, with exception of the always-on mode, voice assistants are not raising much privacy concerns among users (Fruchter et al., 2018; Manikonda et al., 2018).",Ethics,privacy,http://eaontology.linkeddata.es/def/Privacy
0,26,"Similarly, Backe (2018) and Brandom (2019) note that users appear to be okay with trading off their privacy for convenience.",Ethics,privacy,http://eaontology.linkeddata.es/def/Privacy
0,26,"Schwartz (2019), on the other hand, says that the majority of smart speaker users “don’t want their voice assistant’s personalisation ability to improve” because they do not want to share more personal data.",Data protection,personalisation,https://w3id.org/dpv#Personalisation
0,28,It is important that users can trust their voice assistants because of the personal role they fulfil and place they take in one’s private life.,Ethics,life,http://eaontology.linkeddata.es/def/Life
0,28,Users should also be able to trust that companies use personal data in ways that does not violate users’ privacy.,Ethics,privacy,http://eaontology.linkeddata.es/def/Privacy
0,30,"Furthermore, personal voice assistants can threaten the autonomy of users.",Ethics,autonomy,http://eaontology.linkeddata.es/def/Autonomy
0,30,"Personal voice assistants can also threaten the autonomy of users by manipulating choices and choice architectures, for example when they make music recommendations or order products (Danaher, 2018; Davis, 2016).",Ethics,autonomy,http://eaontology.linkeddata.es/def/Autonomy
0,30,"First of all, the use of voice assistants can lead to de-skilling.",Data protection,use,https://w3id.org/dpv#Use
0,30,"not knowing how to manually turn on other devices, or how to search for and filter information.",Data protection,filter,https://w3id.org/dpv#Filter
0,30,"The use of personal voice assistants might also lead to social de-skilling, either by outsourcing human-human communication to personal assistants (Danaher, 2018) or replacing human interaction with personalised interaction with one’s voice assistant (Mattin, 2019).",Data protection,use,https://w3id.org/dpv#Use
0,32,"Another issue has to do with the common user interface of voice assistant systems, which is discriminating women and minorities (Adams & Loideáin, 2019; Bogost, 2018, Kleber, 2018; Prescot, n.d.).",AI Act,user,http://tair.adaptcentre.ie/ontologies/tair/User
0,32,"Another issue has to do with the common user interface of voice assistant systems, which is discriminating women and minorities (Adams & Loideáin, 2019; Bogost, 2018, Kleber, 2018; Prescot, n.d.).",Data protection,user,https://w3id.org/dpv#User
0,32,"Furthermore, the accent and language use of voice assistants are perceived to be ‘white’ and well-educated – thus lacking diversity (Prescot, n.d.).",Data protection,use,https://w3id.org/dpv#Use
0,34,"Growing up with a particular ‘brand’ of voice assistant (say, Alexa), might also cause them to be life-long customers of the respective company (Amazon).",Ethics,life,http://eaontology.linkeddata.es/def/Life
0,34,A personal voice assistant that is personalised on the basis of years of data will make it unattractive to switch from one to another.,Data protection,data,https://w3id.org/dpv#Data
0,34,"Voice assistants create a new way of consuming and “there exists a risk that the voice assistant becomes the gatekeeper by default that may lead to an abuse of market power” (Rabassa, 2019).",Data protection,risk,https://w3id.org/dpv#Risk
0,36,"Similar questions play in the field of robotics and these become more complex as AI systems improves, i.e., when voice assistants become more intelligent.",Ethics,play,http://eaontology.linkeddata.es/def/Play
0,38,Mentioned earlier are the possible negative consequences that personal voice assistants can have on individuals’ autonomy.,Ethics,autonomy,http://eaontology.linkeddata.es/def/Autonomy
0,38,"However, voice assistants can positively affect autonomy too.",Ethics,autonomy,http://eaontology.linkeddata.es/def/Autonomy
0,38,"Finally, the technology does not only raise ethical or legal problems but also comes with a range of benefits, which can be deemed ‘ethical aspects’ of voice assistants.",Data protection,technology,https://w3id.org/dpv#Technology
0,38,The systems also have the potential of detecting cases of domestic violence and audio data can be used as evidence in court.,Data protection,data,https://w3id.org/dpv#Data
