,line #,sentence,Annotator,Named entity,URL
0,5,5.2	Context,Data protection,context,https://w3id.org/dpv#Context
0,6,There is also significant interest in the use of machine learning for personalized diagnosis by extraction of features that could potentially lead to patient-specific therapy planning or support.,Data protection,use,https://w3id.org/dpv#Use
0,6,There is also significant interest in the use of machine learning for personalized diagnosis by extraction of features that could potentially lead to patient-specific therapy planning or support.,Data protection,patient,https://w3id.org/dpv#Patient
0,8,"In general, machine learning processes vast amounts of data to improve diagnosis, treatment, and outcomes for patients in a wide range of healthcare settings.",Data protection,data,https://w3id.org/dpv#Data
0,8,"However, processing sensitive data during the training and the prediction phases, as well as releasing the trained model, raises concerns about privacy, discrimination, informed consent, ownership, trust and transparency.",Data protection,data,https://w3id.org/dpv#Data
0,8,"However, processing sensitive data during the training and the prediction phases, as well as releasing the trained model, raises concerns about privacy, discrimination, informed consent, ownership, trust and transparency.",Data protection,consent,https://w3id.org/dpv#Consent
0,10,5.3	Technology description,Data protection,technology,https://w3id.org/dpv#Technology
0,11,ML algorithms aim to learn how to perform certain tasks by generalizing from data.,Data protection,data,https://w3id.org/dpv#Data
0,11,"Such tasks might include giving accurate predictions or finding structures in data without being explicitly programmed (Samuel, 1995).",Data protection,data,https://w3id.org/dpv#Data
0,13,The model is created based on lots of example data.,Data protection,data,https://w3id.org/dpv#Data
0,13,It means that they adapt the details of the model so that it maps the inputs in the example data to the corresponding outputs.,Data protection,adapt,https://w3id.org/dpv#Adapt
0,13,It means that they adapt the details of the model so that it maps the inputs in the example data to the corresponding outputs.,Data protection,data,https://w3id.org/dpv#Data
0,13,"Once the model has been trained, a data scientist can give it new input, DNA sequences or disease symptoms, for instance, without a label, and the model will give back the output.",Data protection,data,https://w3id.org/dpv#Data
0,13,"Whenever data scientists train a model on examples of input and output, they call it supervised learning.",Data protection,data,https://w3id.org/dpv#Data
0,15,"But sometimes, data scientists do not know what the right output is.",Ethics,right,http://eaontology.linkeddata.es/def/Right
0,15,"But sometimes, data scientists do not know what the right output is.",Data protection,data,https://w3id.org/dpv#Data
0,15,"But sometimes, data scientists do not know what the right output is.",Data protection,right,https://w3id.org/dpv#Right
0,15,Unsupervised learning that utilizes unlabelled data clusters data (clustering) to find structure in the data.,Data protection,data,https://w3id.org/dpv#Data
0,17,"Sometimes, data scientists combine supervised learning with unsupervised learning styles to train a model, which is called semi-supervised learning.",Data protection,data,https://w3id.org/dpv#Data
0,17,Labelling data requires human experts or special devices; hence it can be expensive.,Data protection,data,https://w3id.org/dpv#Data
0,17,Semi-supervised learning aims to classify some of the unlabelled data using the labelled information set to improve the learning process.,Data protection,data,https://w3id.org/dpv#Data
0,21,"An unsupervised model, in contrast, provides unlabelled data that the algorithms try to group a set of samples into a number of clusters by extracting features or patterns.",Risk,group,http://www.w3id.org/vair#Group
0,21,"An unsupervised model, in contrast, provides unlabelled data that the algorithms try to group a set of samples into a number of clusters by extracting features or patterns.",Data protection,data,https://w3id.org/dpv#Data
0,21,"Semi-supervised learning classifies a series of unlabelled data using the labelled information set (Al-Rubaie & Chang, 2018).",Data protection,data,https://w3id.org/dpv#Data
0,24,The input data to an ML algorithm is usually a set of samples.,AI Act,input data,http://tair.adaptcentre.ie/ontologies/tair/InputData
0,24,"Overall, three different phases can be distinguished in the machine learning process: training data and producing precise models, prediction or inference based on the trained model, and releasing the model between different parties for testing new samples or benefiting for the prediction model.",AI Act,training data,http://tair.adaptcentre.ie/ontologies/tair/TrainingData
0,24,"Machine learning (ML) as a field of study gives computers the ability to learn how to provide accurate predictions or find structures in data without being explicitly programmed (Samuel, 1959).",Data protection,data,https://w3id.org/dpv#Data
0,24,The input data to an ML algorithm is usually a set of samples.,Data protection,data,https://w3id.org/dpv#Data
0,24,The ML algorithm then would use the training set to build a model.,Data protection,use,https://w3id.org/dpv#Use
0,24,The ability of the model to accurately predict data is a measure of how well this ML model generalizes the unseen data.,Data protection,data,https://w3id.org/dpv#Data
0,24,The ability of the model to accurately predict data is a measure of how well this ML model generalizes the unseen data.,Data protection,data,https://w3id.org/dpv#Data
0,24,"Overall, three different phases can be distinguished in the machine learning process: training data and producing precise models, prediction or inference based on the trained model, and releasing the model between different parties for testing new samples or benefiting for the prediction model.",Data protection,data,https://w3id.org/dpv#Data
0,26,"In medicine and healthcare, machine learning techniques are adopted to classify, cluster, and analyse large volumes of health data.",Data protection,analyse,https://w3id.org/dpv#Analyse
0,26,"In medicine and healthcare, machine learning techniques are adopted to classify, cluster, and analyse large volumes of health data.",Data protection,data,https://w3id.org/dpv#Data
0,26,"With regard to an amount of data generated in the healthcare area, machine learning techniques can be used to gain insights from large volumes of data.",Data protection,data,https://w3id.org/dpv#Data
0,26,"With regard to an amount of data generated in the healthcare area, machine learning techniques can be used to gain insights from large volumes of data.",Data protection,data,https://w3id.org/dpv#Data
0,26,(2018) classify data in healthcare into four types based on the data sources:,Data protection,data,https://w3id.org/dpv#Data
0,28,"•	Data in medicine, also named medical/clinical data: data in medicine and clinics include various types and large amounts of data generated from hospitals, such as clinical data and medical imaging;",Data protection,data,https://w3id.org/dpv#Data
0,28,"•	Data in medicine, also named medical/clinical data: data in medicine and clinics include various types and large amounts of data generated from hospitals, such as clinical data and medical imaging;",Data protection,data,https://w3id.org/dpv#Data
0,28,"•	Data in medicine, also named medical/clinical data: data in medicine and clinics include various types and large amounts of data generated from hospitals, such as clinical data and medical imaging;",Data protection,data,https://w3id.org/dpv#Data
0,28,"•	Data in medicine, also named medical/clinical data: data in medicine and clinics include various types and large amounts of data generated from hospitals, such as clinical data and medical imaging;",Data protection,data,https://w3id.org/dpv#Data
0,29,"•	Data in public health and behaviour: data in public health and behaviour focus on the physiological data of users that are often collected by portable equipment, such as wearable devices, daily health records, sports, and diet;",Data protection,data,https://w3id.org/dpv#Data
0,29,"•	Data in public health and behaviour: data in public health and behaviour focus on the physiological data of users that are often collected by portable equipment, such as wearable devices, daily health records, sports, and diet;",Data protection,data,https://w3id.org/dpv#Data
0,29,"•	Data in public health and behaviour: data in public health and behaviour focus on the physiological data of users that are often collected by portable equipment, such as wearable devices, daily health records, sports, and diet;",Data protection,data,https://w3id.org/dpv#Data
0,30,"•	Data in the medical experiment: data in medical experiments mainly focus on molecular biology, human body dataset, clinical trials, biology samples, gene sequence, and clinical and medical research laboratory tests and omics data (Hong et al., 2018).",Data protection,data,https://w3id.org/dpv#Data
0,30,"•	Data in the medical experiment: data in medical experiments mainly focus on molecular biology, human body dataset, clinical trials, biology samples, gene sequence, and clinical and medical research laboratory tests and omics data (Hong et al., 2018).",Data protection,data,https://w3id.org/dpv#Data
0,30,"•	Data in the medical experiment: data in medical experiments mainly focus on molecular biology, human body dataset, clinical trials, biology samples, gene sequence, and clinical and medical research laboratory tests and omics data (Hong et al., 2018).",Data protection,data,https://w3id.org/dpv#Data
0,30,"Omics data are the biology information data in the molecular level catalogue, including genomics, proteomics, metabolomics, transcriptomics, epigenomics, lipidomics, immunomics, glycomics, and RNomics (Wu et al., 2017);",Data protection,data,https://w3id.org/dpv#Data
0,30,"Omics data are the biology information data in the molecular level catalogue, including genomics, proteomics, metabolomics, transcriptomics, epigenomics, lipidomics, immunomics, glycomics, and RNomics (Wu et al., 2017);",Data protection,data,https://w3id.org/dpv#Data
0,31,"•	Data in the medical literature: data in medical literature include research articles and structured knowledge produced in the healthcare area (Hong et al., 2018).",Data protection,data,https://w3id.org/dpv#Data
0,31,"•	Data in the medical literature: data in medical literature include research articles and structured knowledge produced in the healthcare area (Hong et al., 2018).",Data protection,data,https://w3id.org/dpv#Data
0,33,"Machine learning shows potential to meet the criteria for success in the healthcare area, including good performance, the algorithm’s ability to reduce the number of tests necessary to obtain reliable diagnosis, and the ability to appropriately deal with missing data.",AI Act,performance,http://tair.adaptcentre.ie/ontologies/tair/Performance
0,33,"Machine learning shows potential to meet the criteria for success in the healthcare area, including good performance, the algorithm’s ability to reduce the number of tests necessary to obtain reliable diagnosis, and the ability to appropriately deal with missing data.",AI Act,missing data,http://tair.adaptcentre.ie/ontologies/tair/MissingData
0,33,"Machine learning shows potential to meet the criteria for success in the healthcare area, including good performance, the algorithm’s ability to reduce the number of tests necessary to obtain reliable diagnosis, and the ability to appropriately deal with missing data.",Data protection,obtain,https://w3id.org/dpv#Obtain
0,33,"Machine learning shows potential to meet the criteria for success in the healthcare area, including good performance, the algorithm’s ability to reduce the number of tests necessary to obtain reliable diagnosis, and the ability to appropriately deal with missing data.",Data protection,data,https://w3id.org/dpv#Data
0,35,"However, there is literate on ethical issues arising in big data, and broadly in AI.",Data protection,data,https://w3id.org/dpv#Data
0,35,"Therefore, what I have done is that I have looked down on ethical issues in big data and AI, and through the lens of what ML is, I conclude the five of the ethical issues of ML, namely privacy, discrimination, informed consent, ownership, and trust and transparency.",Data protection,data,https://w3id.org/dpv#Data
0,35,"Therefore, what I have done is that I have looked down on ethical issues in big data and AI, and through the lens of what ML is, I conclude the five of the ethical issues of ML, namely privacy, discrimination, informed consent, ownership, and trust and transparency.",Data protection,consent,https://w3id.org/dpv#Consent
0,37,"Firstly, key ethical challenges in machine learning will be studied, including a) privacy concerns related to training, inference and sharing the trained model, b) discrimination caused by data linkage and aggregation, inferences, algorithms, and digital divide, c) challenges of obtaining informed consent and different models of informed consent, d) ownership issues, and e) trust and transparency challenges in machine learning.",Ethics,privacy,http://eaontology.linkeddata.es/def/Privacy
0,37,"Firstly, key ethical challenges in machine learning will be studied, including a) privacy concerns related to training, inference and sharing the trained model, b) discrimination caused by data linkage and aggregation, inferences, algorithms, and digital divide, c) challenges of obtaining informed consent and different models of informed consent, d) ownership issues, and e) trust and transparency challenges in machine learning.",Data protection,data,https://w3id.org/dpv#Data
0,37,"Firstly, key ethical challenges in machine learning will be studied, including a) privacy concerns related to training, inference and sharing the trained model, b) discrimination caused by data linkage and aggregation, inferences, algorithms, and digital divide, c) challenges of obtaining informed consent and different models of informed consent, d) ownership issues, and e) trust and transparency challenges in machine learning.",Data protection,consent,https://w3id.org/dpv#Consent
0,37,"Firstly, key ethical challenges in machine learning will be studied, including a) privacy concerns related to training, inference and sharing the trained model, b) discrimination caused by data linkage and aggregation, inferences, algorithms, and digital divide, c) challenges of obtaining informed consent and different models of informed consent, d) ownership issues, and e) trust and transparency challenges in machine learning.",Data protection,consent,https://w3id.org/dpv#Consent
0,37,"Secondly, I will look at the general data protection regulations to explore the suitability of the existing legal framework for reducing or mitigating issues caused by the use of machine learning in healthcare.",Data protection,use,https://w3id.org/dpv#Use
0,39,It should be noted that the main discussion in the sections related to privacy and its related issues is on individual privacy.,Ethics,privacy,http://eaontology.linkeddata.es/def/Privacy
0,39,It should be noted that the main discussion in the sections related to privacy and its related issues is on individual privacy.,Ethics,privacy,http://eaontology.linkeddata.es/def/Privacy
0,39,"However, I refer to group privacy issues in general without discussing group privacy and the right to group privacy in detail.",Ethics,privacy,http://eaontology.linkeddata.es/def/Privacy
0,39,"To assign privacy rights to a group, I need to demonstrate that the collective dimension requires granting specific collective rights, which are different from the already existing rights in the field of privacy and data protection.",Ethics,privacy,http://eaontology.linkeddata.es/def/Privacy
0,39,"To assign privacy rights to a group, I need to demonstrate that the collective dimension requires granting specific collective rights, which are different from the already existing rights in the field of privacy and data protection.",Ethics,privacy,http://eaontology.linkeddata.es/def/Privacy
0,39,"That is, it is important to investigate the possibility that groups have rights to privacy that are not reducible to the privacy of the individuals forming such groups (Taylor et al., 2017).",Ethics,privacy,http://eaontology.linkeddata.es/def/Privacy
0,39,"That is, it is important to investigate the possibility that groups have rights to privacy that are not reducible to the privacy of the individuals forming such groups (Taylor et al., 2017).",Ethics,privacy,http://eaontology.linkeddata.es/def/Privacy
0,39,"Therefore, discussing group rights to privacy and issues caused by violation such a right requires a different document.",Ethics,privacy,http://eaontology.linkeddata.es/def/Privacy
0,39,"Therefore, discussing group rights to privacy and issues caused by violation such a right requires a different document.",Ethics,right,http://eaontology.linkeddata.es/def/Right
0,39,"However, I refer to group privacy issues in general without discussing group privacy and the right to group privacy in detail.",Risk,group,http://www.w3id.org/vair#Group
0,39,"However, I refer to group privacy issues in general without discussing group privacy and the right to group privacy in detail.",Risk,group,http://www.w3id.org/vair#Group
0,39,"However, I refer to group privacy issues in general without discussing group privacy and the right to group privacy in detail.",Risk,group,http://www.w3id.org/vair#Group
0,39,"To assign privacy rights to a group, I need to demonstrate that the collective dimension requires granting specific collective rights, which are different from the already existing rights in the field of privacy and data protection.",Risk,group,http://www.w3id.org/vair#Group
0,39,"In doing so, I need to conceptualize the nature of groups (traditional and ad hoc groups), discuss which type of group can be considered as an autonomous entity and define the right to privacy.",Risk,group,http://www.w3id.org/vair#Group
0,39,"Therefore, discussing group rights to privacy and issues caused by violation such a right requires a different document.",Risk,group,http://www.w3id.org/vair#Group
0,39,"However, I refer to group privacy issues in general without discussing group privacy and the right to group privacy in detail.",Data protection,right,https://w3id.org/dpv#Right
0,39,"To assign privacy rights to a group, I need to demonstrate that the collective dimension requires granting specific collective rights, which are different from the already existing rights in the field of privacy and data protection.",Data protection,data,https://w3id.org/dpv#Data
0,39,"Therefore, discussing group rights to privacy and issues caused by violation such a right requires a different document.",Data protection,right,https://w3id.org/dpv#Right
0,42," This section focuses on challenges about privacy, discrimination, informed consent, ownership, trust and transparency caused by the application of machine learning.",Ethics,privacy,http://eaontology.linkeddata.es/def/Privacy
0,42," This section focuses on challenges about privacy, discrimination, informed consent, ownership, trust and transparency caused by the application of machine learning.",Data protection,consent,https://w3id.org/dpv#Consent
0,44,5.5.1	Privacy,Ethics,privacy,http://eaontology.linkeddata.es/def/Privacy
0,45,This section focuses on privacy issues raised by the application of machine learning in the healthcare area.,Ethics,privacy,http://eaontology.linkeddata.es/def/Privacy
0,45,"However, privacy concerns, which are related to sensitive data for model training and its use for inference, as well as sharing the trained model, are raised.",Ethics,privacy,http://eaontology.linkeddata.es/def/Privacy
0,45,"Furthermore, the leakage of sensitive data through model parameters or predictions is another privacy concern related to sharing or releasing a trained model (Boulemtafes et al., 2020).",Ethics,privacy,http://eaontology.linkeddata.es/def/Privacy
0,45,"Therefore, it is important to study privacy risks that might arise during the different phases of machine learning, i.e., training a model, inference through a model, and releasing a model.",Ethics,privacy,http://eaontology.linkeddata.es/def/Privacy
0,45,"However, privacy concerns, which are related to sensitive data for model training and its use for inference, as well as sharing the trained model, are raised.",Data protection,data,https://w3id.org/dpv#Data
0,45,"However, privacy concerns, which are related to sensitive data for model training and its use for inference, as well as sharing the trained model, are raised.",Data protection,use,https://w3id.org/dpv#Use
0,47,There is persistent disagreement in the literature on privacy’s proper meaning and definition.,Ethics,privacy,http://eaontology.linkeddata.es/def/Privacy
0,47,"However, two terms that figure prominently in the discussion on privacy’s meaning and definition are ‘access’ and ‘control.’ The access account provides the descriptive notion of privacy (what privacy entails) (Macnish, 2020), while the normative notion of privacy (what privacy should entail) defined by control accounts.",Ethics,privacy,http://eaontology.linkeddata.es/def/Privacy
0,47,"However, two terms that figure prominently in the discussion on privacy’s meaning and definition are ‘access’ and ‘control.’ The access account provides the descriptive notion of privacy (what privacy entails) (Macnish, 2020), while the normative notion of privacy (what privacy should entail) defined by control accounts.",Ethics,privacy,http://eaontology.linkeddata.es/def/Privacy
0,47,"However, two terms that figure prominently in the discussion on privacy’s meaning and definition are ‘access’ and ‘control.’ The access account provides the descriptive notion of privacy (what privacy entails) (Macnish, 2020), while the normative notion of privacy (what privacy should entail) defined by control accounts.",Ethics,privacy,http://eaontology.linkeddata.es/def/Privacy
0,47,"However, two terms that figure prominently in the discussion on privacy’s meaning and definition are ‘access’ and ‘control.’ The access account provides the descriptive notion of privacy (what privacy entails) (Macnish, 2020), while the normative notion of privacy (what privacy should entail) defined by control accounts.",Ethics,privacy,http://eaontology.linkeddata.es/def/Privacy
0,47,"However, two terms that figure prominently in the discussion on privacy’s meaning and definition are ‘access’ and ‘control.’ The access account provides the descriptive notion of privacy (what privacy entails) (Macnish, 2020), while the normative notion of privacy (what privacy should entail) defined by control accounts.",Ethics,privacy,http://eaontology.linkeddata.es/def/Privacy
0,47,"Kevin Macnish (2020) argues that “a loss of privacy occurs when there is actual access to that which is deemed private” (Macnish, 2020, p. 9).",Ethics,privacy,http://eaontology.linkeddata.es/def/Privacy
0,47,"Macnish argues, without semantic understanding, there can be no loss of privacy.",Ethics,privacy,http://eaontology.linkeddata.es/def/Privacy
0,47,"Thus, automated systems do not lead to a diminution of privacy when they access private information because they are incapable of semantic understanding (Macnish, 2020).",Ethics,privacy,http://eaontology.linkeddata.es/def/Privacy
0,47,"However, the control account of privacy holds that privacy is a matter of being able to control private information about oneself (Moore, 2003).",Ethics,privacy,http://eaontology.linkeddata.es/def/Privacy
0,47,"However, the control account of privacy holds that privacy is a matter of being able to control private information about oneself (Moore, 2003).",Ethics,privacy,http://eaontology.linkeddata.es/def/Privacy
0,47,"However, two terms that figure prominently in the discussion on privacy’s meaning and definition are ‘access’ and ‘control.’ The access account provides the descriptive notion of privacy (what privacy entails) (Macnish, 2020), while the normative notion of privacy (what privacy should entail) defined by control accounts.",Data protection,access,https://w3id.org/dpv#Access
0,47,"However, two terms that figure prominently in the discussion on privacy’s meaning and definition are ‘access’ and ‘control.’ The access account provides the descriptive notion of privacy (what privacy entails) (Macnish, 2020), while the normative notion of privacy (what privacy should entail) defined by control accounts.",Data protection,access,https://w3id.org/dpv#Access
0,47,"Kevin Macnish (2020) argues that “a loss of privacy occurs when there is actual access to that which is deemed private” (Macnish, 2020, p. 9).",Data protection,access,https://w3id.org/dpv#Access
0,47,"Thus, automated systems do not lead to a diminution of privacy when they access private information because they are incapable of semantic understanding (Macnish, 2020).",Data protection,access,https://w3id.org/dpv#Access
0,47,"Thus, any informational practice that leads to the loss of or reduction in exercising control over personal information is morally problematic as it causes harm to the individual whose data are stored or processed.",Data protection,harm,https://w3id.org/dpv#Harm
0,47,"Thus, any informational practice that leads to the loss of or reduction in exercising control over personal information is morally problematic as it causes harm to the individual whose data are stored or processed.",Data protection,data,https://w3id.org/dpv#Data
0,49,"With respect to the above discussion, fully automated systems do not raise concerns about privacy from the descriptive perspective, while partially automated systems increase privacy risks as such systems require individuals to access the sensitive data and process them.",Ethics,privacy,http://eaontology.linkeddata.es/def/Privacy
0,49,"With respect to the above discussion, fully automated systems do not raise concerns about privacy from the descriptive perspective, while partially automated systems increase privacy risks as such systems require individuals to access the sensitive data and process them.",Ethics,privacy,http://eaontology.linkeddata.es/def/Privacy
0,49,"Thus, it is more likely that a software developer/ programmer has access to sensitive and private information, which leads to a diminution of privacy, from the descriptive perspective.",Ethics,privacy,http://eaontology.linkeddata.es/def/Privacy
0,49,"Overall, since privacy as an access issue would be a contingent problem in ML, software developers/ programmers play an important role in mitigating or reducing privacy issues.",Ethics,play,http://eaontology.linkeddata.es/def/Play
0,49,"Overall, since privacy as an access issue would be a contingent problem in ML, software developers/ programmers play an important role in mitigating or reducing privacy issues.",Ethics,privacy,http://eaontology.linkeddata.es/def/Privacy
0,49,"It is important to note that for individuals with sensitive information in their health records, there is a risk that information will be observed during the training of a model phase (Neamatullah et al., 2008; Wellner et al., 2007).",Data protection,risk,https://w3id.org/dpv#Risk
0,49,"Thus, it is more likely that a software developer/ programmer has access to sensitive and private information, which leads to a diminution of privacy, from the descriptive perspective.",Data protection,access,https://w3id.org/dpv#Access
0,49,Unauthorized access without medical justification raises concerns about misuse (abuse) of data.,Data protection,justification,https://w3id.org/dpv#Justification
0,49,Unauthorized access without medical justification raises concerns about misuse (abuse) of data.,Data protection,data,https://w3id.org/dpv#Data
0,49,"Loss of faith in confidential health service and general loss of public trust in the medical profession are harms arising from misuse of data (Becker, 2015).",Data protection,data,https://w3id.org/dpv#Data
0,49,"Overall, since privacy as an access issue would be a contingent problem in ML, software developers/ programmers play an important role in mitigating or reducing privacy issues.",Data protection,access,https://w3id.org/dpv#Access
0,51,"Notably, privacy as a control issue is a necessary problem in ML which arises as soon as data are collected either by fully or by partially automated systems.",Ethics,privacy,http://eaontology.linkeddata.es/def/Privacy
0,51,"Once an individual lost their control over their own data, privacy issues arise.",Ethics,privacy,http://eaontology.linkeddata.es/def/Privacy
0,51,"Since privacy as a control issue is a necessary problem in ML, ethicists, lawyers, or politicians play an important role in mitigating or reducing privacy issues.",Ethics,privacy,http://eaontology.linkeddata.es/def/Privacy
0,51,"Since privacy as a control issue is a necessary problem in ML, ethicists, lawyers, or politicians play an important role in mitigating or reducing privacy issues.",Ethics,privacy,http://eaontology.linkeddata.es/def/Privacy
0,51,"Therefore, for the purpose of this study, I take normative account of privacy and discuss privacy issues from this perspective.",Ethics,privacy,http://eaontology.linkeddata.es/def/Privacy
0,51,"I argue that the de-anonymisation (re-identification) process, revealing private or sensitive information, generating or prediction of information, and determining members of a group raise concerns about privacy.",Ethics,privacy,http://eaontology.linkeddata.es/def/Privacy
0,51,"I argue that the de-anonymisation (re-identification) process, revealing private or sensitive information, generating or prediction of information, and determining members of a group raise concerns about privacy.",Risk,group,http://www.w3id.org/vair#Group
0,51,"Notably, privacy as a control issue is a necessary problem in ML which arises as soon as data are collected either by fully or by partially automated systems.",Data protection,data,https://w3id.org/dpv#Data
0,51,"Once an individual lost their control over their own data, privacy issues arise.",Data protection,data,https://w3id.org/dpv#Data
0,51,"Therefore, for the purpose of this study, I take normative account of privacy and discuss privacy issues from this perspective.",Data protection,purpose,https://w3id.org/dpv#Purpose
0,53,"Linking databases poses a risk to data subject privacy by increasing the risk of creating a link to data subject identity (re-identification) (Torra & Navarro-Arribas, 2016).",Ethics,privacy,http://eaontology.linkeddata.es/def/Privacy
0,53,"Thus, re-identification and revealing private information cause privacy issues in this phase.",Ethics,privacy,http://eaontology.linkeddata.es/def/Privacy
0,53,"Firstly, during the training phase, it is usual for ML to share and link databases between different ML algorithms to improve the quality of information.",Data protection,share,https://w3id.org/dpv#Share
0,53,"Linking databases poses a risk to data subject privacy by increasing the risk of creating a link to data subject identity (re-identification) (Torra & Navarro-Arribas, 2016).",Data protection,risk,https://w3id.org/dpv#Risk
0,53,"Linking databases poses a risk to data subject privacy by increasing the risk of creating a link to data subject identity (re-identification) (Torra & Navarro-Arribas, 2016).",Data protection,data subject,https://w3id.org/dpv#DataSubject
0,53,"These issues raise concerns about invasive profiling, inference and discrimination (Wachter, 2018).",Data protection,profiling,https://w3id.org/dpv#Profiling
0,55,"Secondly, inferences through a model pose a risk to data subject privacy by generating information/ predicting about the data subject.",Ethics,privacy,http://eaontology.linkeddata.es/def/Privacy
0,55,"Secondly, inferences through a model pose a risk to data subject privacy by generating information/ predicting about the data subject.",Data protection,data,https://w3id.org/dpv#Data
0,55,The scope and value of inferences create an uncertain situation and make it difficult to obtain informed consent.,Data protection,scope,https://w3id.org/dpv#Scope
0,57,"Finally, releasing a model poses a risk to data subject privacy by determining whether the person was a member of the training set used to build the ML model (Al-Rubaie & Chang, 2018).",Ethics,privacy,http://eaontology.linkeddata.es/def/Privacy
0,57,"Such inferential analysis reduces data subjects’ control over their information as it detaches from their awareness or oversight of this process (Wachter, 2018), which then leads to privacy issues from the normative perspective.",Ethics,privacy,http://eaontology.linkeddata.es/def/Privacy
0,57,"Finally, releasing a model poses a risk to data subject privacy by determining whether the person was a member of the training set used to build the ML model (Al-Rubaie & Chang, 2018).",Data protection,member,https://w3id.org/dpv#Member
0,59,"Thus far, privacy issues from descriptive and normative perspectives have been discussed.",Ethics,privacy,http://eaontology.linkeddata.es/def/Privacy
0,59,"Some privacy scholars, however, argue that the scope of data being collected can also raise concerns about privacy.",Ethics,privacy,http://eaontology.linkeddata.es/def/Privacy
0,59,"Some privacy scholars, however, argue that the scope of data being collected can also raise concerns about privacy.",Ethics,privacy,http://eaontology.linkeddata.es/def/Privacy
0,59,"Extending the lifespan of data increases the risks of privacy violations (Mittelstadt & Floridi, 2015).",Ethics,privacy,http://eaontology.linkeddata.es/def/Privacy
0,59,"With automated and autonomous collection by information and communication technologies (ICTs), the scope (and scale) of data has grown exponentially in comparison with the past two decades when data collection has been limited by human capabilities and cost of automation.",Data protection,data,https://w3id.org/dpv#Data
0,59,"In the age of big data, more personal information and highly detailed data can be collected and analysed.",Data protection,data,https://w3id.org/dpv#Data
0,59,"In the age of big data, more personal information and highly detailed data can be collected and analysed.",Data protection,data,https://w3id.org/dpv#Data
0,59,"Furthermore, the lifespan of data collected today may be extended insofar as data would not be forgotten and be equally accessible of the same quality in the future.",Data protection,data,https://w3id.org/dpv#Data
0,59,"Furthermore, the lifespan of data collected today may be extended insofar as data would not be forgotten and be equally accessible of the same quality in the future.",Data protection,data,https://w3id.org/dpv#Data
0,59,"Extending the lifespan of data increases the risks of privacy violations (Mittelstadt & Floridi, 2015).",Data protection,data,https://w3id.org/dpv#Data
0,61,"However, collecting, storing, sharing, and analysing datasets threatens the privacy of those whose data are processed.",Ethics,privacy,http://eaontology.linkeddata.es/def/Privacy
0,61,Privacy and anonymisation issues are frequently addressed in the literature on big data analytics and machine learning.,Ethics,privacy,http://eaontology.linkeddata.es/def/Privacy
0,61,"To summarise, data subjects (patients) records from large public and private healthcare systems may accelerate the development of machine learning that can significantly enhance the quality and availability of health care.",Data protection,data,https://w3id.org/dpv#Data
0,61,"However, collecting, storing, sharing, and analysing datasets threatens the privacy of those whose data are processed.",Data protection,data,https://w3id.org/dpv#Data
0,61,Privacy and anonymisation issues are frequently addressed in the literature on big data analytics and machine learning.,Data protection,data,https://w3id.org/dpv#Data
0,64,"Anonymisation, removing identifying information, is a requirement for protecting data subjects’ privacy in aggregating data.",Ethics,privacy,http://eaontology.linkeddata.es/def/Privacy
0,64,"However, there is the possibility of de-anonymisation through data concerning the ethnic background, locational data, other metadata, health records, or even small pieces of identified genetic data (Choudhury et al., 2014).",AI Act,through data,http://tair.adaptcentre.ie/ontologies/tair/ThroughData
0,64,"Anonymisation, removing identifying information, is a requirement for protecting data subjects’ privacy in aggregating data.",Data protection,data,https://w3id.org/dpv#Data
0,64,"However, there is the possibility of de-anonymisation through data concerning the ethnic background, locational data, other metadata, health records, or even small pieces of identified genetic data (Choudhury et al., 2014).",Data protection,data,https://w3id.org/dpv#Data
0,64,"However, there is the possibility of de-anonymisation through data concerning the ethnic background, locational data, other metadata, health records, or even small pieces of identified genetic data (Choudhury et al., 2014).",Data protection,data,https://w3id.org/dpv#Data
0,64,"However, there is the possibility of de-anonymisation through data concerning the ethnic background, locational data, other metadata, health records, or even small pieces of identified genetic data (Choudhury et al., 2014).",Data protection,data,https://w3id.org/dpv#Data
0,66,"The use of anonymized health information poses privacy risks to the individuals whose records are accessed, analysed, and disclosed.",Ethics,privacy,http://eaontology.linkeddata.es/def/Privacy
0,66,"De-anonymized of health data in biobanks is also possible using available public databases (McGuire & Gibbs, 2006), thereby raising the privacy risk to the data subjects.",Ethics,privacy,http://eaontology.linkeddata.es/def/Privacy
0,66,"Therefore, anonymisation is a weak safeguard to protect privacy.",Ethics,privacy,http://eaontology.linkeddata.es/def/Privacy
0,66,"That is, it is possible to identify an individual’s data in a pooled or aggregated sample.",AI Act,’s data,http://tair.adaptcentre.ie/ontologies/tair/’SData
0,66,"Lastly, anonymized process is relevant only to the identifiable individual, whereas group-level harms from analysis of aggregated data are clearly possible.",Risk,group,http://www.w3id.org/vair#Group
0,66,"The use of anonymized health information poses privacy risks to the individuals whose records are accessed, analysed, and disclosed.",Data protection,use,https://w3id.org/dpv#Use
0,66,"Firstly, the anonymisation process of health information may still require that the individuals remove the identifiers.",Data protection,remove,https://w3id.org/dpv#Remove
0,66,"For individuals with sensitive information in their health records, there is a risk that information will be observed during the process of d anonymisation (Neamatullah et al., 2008).",Data protection,risk,https://w3id.org/dpv#Risk
0,66,"De-anonymized of health data in biobanks is also possible using available public databases (McGuire & Gibbs, 2006), thereby raising the privacy risk to the data subjects.",Data protection,data,https://w3id.org/dpv#Data
0,66,"That is, it is possible to identify an individual’s data in a pooled or aggregated sample.",Data protection,data,https://w3id.org/dpv#Data
0,66,"Lastly, anonymized process is relevant only to the identifiable individual, whereas group-level harms from analysis of aggregated data are clearly possible.",Data protection,data,https://w3id.org/dpv#Data
0,66,"Therefore, anonymisation is a weak safeguard to protect privacy.",Data protection,safeguard,https://w3id.org/dpv#Safeguard
0,69," This section discusses the main elements that might cause discrimination or inequality in machine learning, including data linkage or aggregation, inferences, algorithms and, digital divide.",Data protection,data,https://w3id.org/dpv#Data
0,71,5.5.3.1	Data linkage and aggregation: profiling and discrimination,Data protection,data,https://w3id.org/dpv#Data
0,71,5.5.3.1	Data linkage and aggregation: profiling and discrimination,Data protection,profiling,https://w3id.org/dpv#Profiling
0,73,Linking datasets or combining data with other datasets are the possible ways of the profiling that offer grounds for discrimination.,Data protection,data,https://w3id.org/dpv#Data
0,73,Linking datasets or combining data with other datasets are the possible ways of the profiling that offer grounds for discrimination.,Data protection,profiling,https://w3id.org/dpv#Profiling
0,73,"Unpredictable profiling can result from data sharing, in particular, when data are linked to a single data subject identity (Roman et al., 2011).",Data protection,profiling,https://w3id.org/dpv#Profiling
0,73,"Unpredictable profiling can result from data sharing, in particular, when data are linked to a single data subject identity (Roman et al., 2011).",Data protection,data,https://w3id.org/dpv#Data
0,73,"Unpredictable profiling can result from data sharing, in particular, when data are linked to a single data subject identity (Roman et al., 2011).",Data protection,data,https://w3id.org/dpv#Data
0,73,"Unpredictable profiling can result from data sharing, in particular, when data are linked to a single data subject identity (Roman et al., 2011).",Data protection,data subject,https://w3id.org/dpv#DataSubject
0,73,"The data about the data subject can be used in a service which can be personalised based upon past behaviours and preferences, and inferences drawn from these data.",Data protection,data subject,https://w3id.org/dpv#DataSubject
0,73,"The data about the data subject can be used in a service which can be personalised based upon past behaviours and preferences, and inferences drawn from these data.",Data protection,data,https://w3id.org/dpv#Data
0,73,"Even if each dataset is handled responsibly and appropriately de-identified, different algorithms can be used to predict data subjects’ behaviour and match their preferences (Zarsky, 2013).",Data protection,match,https://w3id.org/dpv#Match
0,75,"De Vries argues that the penetration of machine profiling and automatic classification practices into each of our every day’s activities could lead to a general increase of discrimination in many sectors to a level that might make discrimination perceived as a legitimate practice in a constitutional democracy (de Vries, 2010).",Data protection,profiling,https://w3id.org/dpv#Profiling
0,77,"Lack of sleep-which a Fitbit tracks-has been linked to poor psychological well-being, health problems, poor cognitive performance, and negative emotions such as anger, depression, sadness, and fear.” (Peppet, 2014, p. 119).",AI Act,performance,http://tair.adaptcentre.ie/ontologies/tair/Performance
0,77,"Profiling can also lead to unfair discrimination (e.g., economic or gender-based).",Data protection,profiling,https://w3id.org/dpv#Profiling
0,77,The data linked to a single data subject can be used by third parties for various purposes with which the individuals would not agree if asked.,Data protection,data,https://w3id.org/dpv#Data
0,77,The data linked to a single data subject can be used by third parties for various purposes with which the individuals would not agree if asked.,Data protection,data,https://w3id.org/dpv#Data
0,77,"For example, employers as a third party could make inferences about  “impulsivity and the inability to delay gratification both of which might be inferred from one’s exercise habits correlate with alcohol and drug abuse, disordered eating behaviour, cigarette smoking, higher credit-card debt, and lower credit scores.",Data protection,third party,https://w3id.org/dpv#ThirdParty
0,77,"explain that these data can also be used by data controllers for “monitoring people’s online behaviour and using the information collected to show people individually targeted advertisements” (Boerman et al., 2017, p. 363).",Data protection,data,https://w3id.org/dpv#Data
0,77,"It is important to note that even non-sensitive data (e.g., postcodes) can lead to discrimination because sensitive information can still be inferred when datasets are linked.",Data protection,data,https://w3id.org/dpv#Data
0,80,"In this way, such emerging techniques pose risks on the aggregate level, namely a clustered group of people generated or discovered by a feature shared by all individuals in the group (Taylor et al., 2017).",Risk,group,http://www.w3id.org/vair#Group
0,80,"In this way, such emerging techniques pose risks on the aggregate level, namely a clustered group of people generated or discovered by a feature shared by all individuals in the group (Taylor et al., 2017).",Risk,group,http://www.w3id.org/vair#Group
0,80,"Artificial intelligence and machine learning technologies are capable of analysing large datasets to sort data, find patterns, and make predictions.",Data protection,data,https://w3id.org/dpv#Data
0,80,"The nature of the data generated based upon that analysis is inferential, i.e., these data infer rather than prove or demonstrate information about people.",Data protection,data,https://w3id.org/dpv#Data
0,80,"The nature of the data generated based upon that analysis is inferential, i.e., these data infer rather than prove or demonstrate information about people.",Data protection,data,https://w3id.org/dpv#Data
0,80,"The nature of the data generated based upon that analysis is inferential, i.e., these data infer rather than prove or demonstrate information about people.",Data protection,infer,https://w3id.org/dpv#Infer
0,80,"The creation of inferred data provides new categories of information that were not previously available, such as accurate predictions about the future health of those whose data are analysed (O'Callaghan, 2018).",Data protection,data,https://w3id.org/dpv#Data
0,80,"The creation of inferred data provides new categories of information that were not previously available, such as accurate predictions about the future health of those whose data are analysed (O'Callaghan, 2018).",Data protection,data,https://w3id.org/dpv#Data
0,80,"Thus, data analytics technologies are used to formulate groups based on new categories of information, and the kinds of actions and interventions they facilitate are aimed beyond the individual.",Data protection,thus,https://w3id.org/dpv#Thus
0,80,"Thus, data analytics technologies are used to formulate groups based on new categories of information, and the kinds of actions and interventions they facilitate are aimed beyond the individual.",Data protection,data,https://w3id.org/dpv#Data
0,81,"Consider the case when inferential data, a set of patterns, for example, extracted from datasets may reveal sensitive information about a group in the training population, and decision rules based on such data may lead to unfair discrimination against the group, depending on what is represented in the training cases.",AI Act,training population,http://tair.adaptcentre.ie/ontologies/tair/TrainingPopulation
0,81,"Consider the case when inferential data, a set of patterns, for example, extracted from datasets may reveal sensitive information about a group in the training population, and decision rules based on such data may lead to unfair discrimination against the group, depending on what is represented in the training cases.",Risk,group,http://www.w3id.org/vair#Group
0,81,"Consider the case when inferential data, a set of patterns, for example, extracted from datasets may reveal sensitive information about a group in the training population, and decision rules based on such data may lead to unfair discrimination against the group, depending on what is represented in the training cases.",Risk,group,http://www.w3id.org/vair#Group
0,81,"Therefore, inferences drawn from the data may result in discrimination against a classified or clustered group generated or discovered by algorithms.",Risk,group,http://www.w3id.org/vair#Group
0,81,"Consider the case when inferential data, a set of patterns, for example, extracted from datasets may reveal sensitive information about a group in the training population, and decision rules based on such data may lead to unfair discrimination against the group, depending on what is represented in the training cases.",Data protection,data,https://w3id.org/dpv#Data
0,81,"Consider the case when inferential data, a set of patterns, for example, extracted from datasets may reveal sensitive information about a group in the training population, and decision rules based on such data may lead to unfair discrimination against the group, depending on what is represented in the training cases.",Data protection,data,https://w3id.org/dpv#Data
0,81,"Therefore, inferences drawn from the data may result in discrimination against a classified or clustered group generated or discovered by algorithms.",Data protection,data,https://w3id.org/dpv#Data
0,84,"These include target variable and class labels, biased data in the training model, the bias in the data collection, the complexity and opaqueness of machine learning algorithms, and the feature selection or misspecification model.",AI Act,training model,http://tair.adaptcentre.ie/ontologies/tair/TrainingModel
0,84,"These include target variable and class labels, biased data in the training model, the bias in the data collection, the complexity and opaqueness of machine learning algorithms, and the feature selection or misspecification model.",Data protection,data,https://w3id.org/dpv#Data
0,84,"These include target variable and class labels, biased data in the training model, the bias in the data collection, the complexity and opaqueness of machine learning algorithms, and the feature selection or misspecification model.",Data protection,data,https://w3id.org/dpv#Data
0,88,"If the training data is contaminated with discriminatory or prejudiced cases, the system will assume them as valid examples to learn from and reproduce discrimination in its own outcomes (Schermer, 2011).",AI Act,training data,http://tair.adaptcentre.ie/ontologies/tair/TrainingData
0,88,Another cause of discrimination is related to biased data in the training model.,Data protection,data,https://w3id.org/dpv#Data
0,88,"If the training data is contaminated with discriminatory or prejudiced cases, the system will assume them as valid examples to learn from and reproduce discrimination in its own outcomes (Schermer, 2011).",Data protection,data,https://w3id.org/dpv#Data
0,88,"Even if computer scientists do not have a prior desire to judge people based on particular characteristics, predictive algorithms may learn to discriminate based on biased data.",Data protection,data,https://w3id.org/dpv#Data
0,88,"Therefore, there is a risk of inadvertently discriminating against specific groups or individuals (Schermer, 2011).",Data protection,risk,https://w3id.org/dpv#Risk
0,90,"Furthermore, the bias in the data collection, which can present itself as an underrepresentation of specific groups or an overrepresentation in the dataset, can cause additional issues in the training data.",AI Act,training data,http://tair.adaptcentre.ie/ontologies/tair/TrainingData
0,90,"While underrepresentation might result in unfair or unequal treatment, overrepresentation might result in a “disproportioned attention to a protected class group, and the increased scrutiny may lead to a higher probability of observing a target transgression” (d’Alessandro et al., 2017, p. 13).",Risk,group,http://www.w3id.org/vair#Group
0,90,The risk of underrepresentation may occur when a protected group has a smaller sample size than other groups in data.,Risk,group,http://www.w3id.org/vair#Group
0,90,"For example, when we think about the logical relations in African American women groups vs. women or African American groups, differences in sample sizes between groups represent a group more than the others, which will dominate the learning algorithm.",Risk,group,http://www.w3id.org/vair#Group
0,90,"Furthermore, the bias in the data collection, which can present itself as an underrepresentation of specific groups or an overrepresentation in the dataset, can cause additional issues in the training data.",Data protection,data,https://w3id.org/dpv#Data
0,90,"Furthermore, the bias in the data collection, which can present itself as an underrepresentation of specific groups or an overrepresentation in the dataset, can cause additional issues in the training data.",Data protection,data,https://w3id.org/dpv#Data
0,90,"use the word discrimination to mean the “differentiated (and usually negative) treatment of an individual based on membership in some legally protected class” (d’Alessandro et al., 2017, p. 3).",Data protection,use,https://w3id.org/dpv#Use
0,90,The risk of underrepresentation may occur when a protected group has a smaller sample size than other groups in data.,Data protection,risk,https://w3id.org/dpv#Risk
0,90,The risk of underrepresentation may occur when a protected group has a smaller sample size than other groups in data.,Data protection,data,https://w3id.org/dpv#Data
0,90,"On the other hand, an example of the risk of overrepresentation in the employment context is a manager who monitors ex-convicts or African Americans due to some preconceived prejudice.",Data protection,risk,https://w3id.org/dpv#Risk
0,90,"On the other hand, an example of the risk of overrepresentation in the employment context is a manager who monitors ex-convicts or African Americans due to some preconceived prejudice.",Data protection,context,https://w3id.org/dpv#Context
0,90,"Disproportionate sampling (or monitoring) of a protected class may increase the likelihood of observing the negative behaviour and, thus, inducing a correlation with a given class (d’Alessandro et al., 2017).",Data protection,likelihood,https://w3id.org/dpv#Likelihood
0,94,False-positive errors could cause significant harm to an individual in a protected class.,Ethics,harm,http://eaontology.linkeddata.es/def/Harm
0,94,Those who collect or analyse the data decide what kind of attribute or features they want to observe and take into account in their decision-making processes.,Data protection,observe,https://w3id.org/dpv#Observe
0,94,False-positive errors could cause significant harm to an individual in a protected class.,Data protection,harm,https://w3id.org/dpv#Harm
0,98,"•	Direct and voluntary discrimination: classifiers in machine learning might result in discrimination against minorities or disadvantaged groups on the basis of sensitive discriminatory attributes related to group members such as race, gender or sexual orientation (Holtzhausen, 2016);",Risk,group,http://www.w3id.org/vair#Group
0,99,"•	·Economic or marketing discrimination: algorithms might identify less capable, such as elder individuals, and prey on them with targeted advertisements, thereby exploiting their vulnerability, or might treat different people unequally, for example, by inequality in pricing and offering insurance based on their profiles (Newell & Marabelli, 2015);",Data protection,marketing,https://w3id.org/dpv#Marketing
0,100,"•	Discrimination based on health prediction: predictive, and not actual, health data might result in the unequal treatment or discrimination of individuals (Hofman, 2010).",Data protection,data,https://w3id.org/dpv#Data
0,102,"Overall, defining target variables and class labels, training data, collecting data, the complexity of algorithms, and selecting features or attributes can cause discriminatory outcomes in machine learning.",AI Act,training data,http://tair.adaptcentre.ie/ontologies/tair/TrainingData
0,102,"Involuntary and accidental, direct and voluntary, economic or marketing, and discrimination based on health profiles are four types of discrimination caused by algorithmic mechanisms.",Data protection,marketing,https://w3id.org/dpv#Marketing
0,105,Machine learning technologies like any modern information and communication technology or practice can create digital divides.,Data protection,technology,https://w3id.org/dpv#Technology
0,105,"identify nine causes of the digital divide, which result in inequality, injustice, or discrimination, namely skills, resources, geographical location, age, income, gender, education, race (Favaretto et al., 2019).",Data protection,location,https://w3id.org/dpv#Location
0,105,"The use of machine learning, for example, creates the gap between those whose information is regularly collected or analysed and those who is not, because they do not routinely engage in data-generating practices (Lerman, 2013).",Data protection,use,https://w3id.org/dpv#Use
0,105,"The use of machine learning, for example, creates the gap between those whose information is regularly collected or analysed and those who is not, because they do not routinely engage in data-generating practices (Lerman, 2013).",Data protection,data,https://w3id.org/dpv#Data
0,105,"Bakken and Reame argue that data are mainly gathered from white, educated people (Bakken & Reame, 2016).",Data protection,data,https://w3id.org/dpv#Data
0,107,"Burrell (2016) discusses the creation of new digital inequality, arguing that discrimination may arise due to the difference in the distribution of computation resources and processing skills.",Data protection,burrell (,https://w3id.org/dpv#Burrell(
0,107,"Burrell (2016) discusses the creation of new digital inequality, arguing that discrimination may arise due to the difference in the distribution of computation resources and processing skills.",Data protection,processing,https://w3id.org/dpv#Processing
0,109,"It may be possible to express the digital divides are ethically problematic in terms of justice in that knowledge developed from big data analytics, or machine learning, may favour populations from those whose data is collected, and also it is more likely to widen the existing gap in medical practice and knowledge between ‘‘Euro-Americans of middle to upper socio-economic status’’ and others (Lewis et al., 2012, p. 2).",Ethics,justice,http://eaontology.linkeddata.es/def/Justice
0,109,"It may be possible to express the digital divides are ethically problematic in terms of justice in that knowledge developed from big data analytics, or machine learning, may favour populations from those whose data is collected, and also it is more likely to widen the existing gap in medical practice and knowledge between ‘‘Euro-Americans of middle to upper socio-economic status’’ and others (Lewis et al., 2012, p. 2).",Data protection,data,https://w3id.org/dpv#Data
0,109,"It may be possible to express the digital divides are ethically problematic in terms of justice in that knowledge developed from big data analytics, or machine learning, may favour populations from those whose data is collected, and also it is more likely to widen the existing gap in medical practice and knowledge between ‘‘Euro-Americans of middle to upper socio-economic status’’ and others (Lewis et al., 2012, p. 2).",Data protection,data,https://w3id.org/dpv#Data
0,109,"It may be possible to express the digital divides are ethically problematic in terms of justice in that knowledge developed from big data analytics, or machine learning, may favour populations from those whose data is collected, and also it is more likely to widen the existing gap in medical practice and knowledge between ‘‘Euro-Americans of middle to upper socio-economic status’’ and others (Lewis et al., 2012, p. 2).",Data protection,status,https://w3id.org/dpv#Status
0,112,"Data subjects may be unaware of the potential value and inferences can be drawn from their data, as well as the extent to which their data are accessible to third parties outside the context or purpose for which they were created (Boyd & Crawford, 2012).",Data protection,data,https://w3id.org/dpv#Data
0,112,"Data subjects may be unaware of the potential value and inferences can be drawn from their data, as well as the extent to which their data are accessible to third parties outside the context or purpose for which they were created (Boyd & Crawford, 2012).",Data protection,data,https://w3id.org/dpv#Data
0,112,"Data subjects may be unaware of the potential value and inferences can be drawn from their data, as well as the extent to which their data are accessible to third parties outside the context or purpose for which they were created (Boyd & Crawford, 2012).",Data protection,data,https://w3id.org/dpv#Data
0,114,"(2014) argue that informed consent that is taken for participation in the primary study cannot cover potentially unrelated investigations that could follow from sharing, aggregating, or even repurposing data in the wider community (Choudhury et al., 2014).",Data protection,data,https://w3id.org/dpv#Data
0,114,Obtaining informed consent is problematic because the data will reveal unpredictable features about data subjects in the future that are uncertain at the time of consent.,Data protection,data,https://w3id.org/dpv#Data
0,114,Obtaining informed consent is problematic because the data will reveal unpredictable features about data subjects in the future that are uncertain at the time of consent.,Data protection,consent,https://w3id.org/dpv#Consent
0,114,"Consequently, consent cannot be informed because data subjects are unaware of the future uses and consequences of their data (Mittelstadt & Floridi, 2015), and what values and inferences can be drawn from their data (Boyd & Crawford, 2012).",Data protection,consent,https://w3id.org/dpv#Consent
0,114,"Consequently, consent cannot be informed because data subjects are unaware of the future uses and consequences of their data (Mittelstadt & Floridi, 2015), and what values and inferences can be drawn from their data (Boyd & Crawford, 2012).",Data protection,data,https://w3id.org/dpv#Data
0,114,"Consequently, consent cannot be informed because data subjects are unaware of the future uses and consequences of their data (Mittelstadt & Floridi, 2015), and what values and inferences can be drawn from their data (Boyd & Crawford, 2012).",Data protection,data,https://w3id.org/dpv#Data
0,116,"However, these novel approaches to consent raise concerns about the autonomy of data subjects because they do not have to re-consent for each study or each stage of research (Caulfield, 2007).",Ethics,autonomy,http://eaontology.linkeddata.es/def/Autonomy
0,116,"Due to the uncertainties of inferential analytics and the potential risks and benefits of research, which are often unknown at the time of initial data collection (Williams & Pigeot, 2016), obtaining informed consent is difficult, if not impossible.",Data protection,data,https://w3id.org/dpv#Data
0,116,"Due to the uncertainties of inferential analytics and the potential risks and benefits of research, which are often unknown at the time of initial data collection (Williams & Pigeot, 2016), obtaining informed consent is difficult, if not impossible.",Data protection,pigeot,https://w3id.org/dpv#Pigeot
0,116,"Due to the uncertainties of inferential analytics and the potential risks and benefits of research, which are often unknown at the time of initial data collection (Williams & Pigeot, 2016), obtaining informed consent is difficult, if not impossible.",Data protection,consent,https://w3id.org/dpv#Consent
0,116,"Many scholars, however, take the view that in cases where the specifics of future values and uses of data are unknown, the general (broad) or blanket consent is acceptable.",Data protection,data,https://w3id.org/dpv#Data
0,116,"Many scholars, however, take the view that in cases where the specifics of future values and uses of data are unknown, the general (broad) or blanket consent is acceptable.",Data protection,consent,https://w3id.org/dpv#Consent
0,116,"In the blanket consent, the data subjects can actively consent once for the current study and all future research involving the general use of their information.",Data protection,use,https://w3id.org/dpv#Use
0,116,"General, open, and generic are other terms for this kind of consent.",Data protection,consent,https://w3id.org/dpv#Consent
0,116,"However, these novel approaches to consent raise concerns about the autonomy of data subjects because they do not have to re-consent for each study or each stage of research (Caulfield, 2007).",Data protection,consent,https://w3id.org/dpv#Consent
0,116,"However, these novel approaches to consent raise concerns about the autonomy of data subjects because they do not have to re-consent for each study or each stage of research (Caulfield, 2007).",Data protection,data,https://w3id.org/dpv#Data
0,116,"However, these novel approaches to consent raise concerns about the autonomy of data subjects because they do not have to re-consent for each study or each stage of research (Caulfield, 2007).",Data protection,consent,https://w3id.org/dpv#Consent
0,118,"Given the extensive uncertainty over what collected data may reveal in the future, two main approaches have been developed to eliminate the need for consent: by relying upon altruism (Choudhury et al., 2014), or solidarity-based approach instead of autonomy-based consent approaches (Prainsack & Buyx, 2013).",Ethics,autonomy,http://eaontology.linkeddata.es/def/Autonomy
0,118,"Unlike the autonomy-based consent approaches, this approach provides data subjects with a ‘mission statement’, information about the research questions and contexts, the potential commercial value of the data, future uses, feedback procedures and risks and benefits, so as to establish   ‘‘contractual’’ rather than consent basis for the research relationship (Prainsack and Buyx 2013, pp.",Ethics,autonomy,http://eaontology.linkeddata.es/def/Autonomy
0,118,"Given the extensive uncertainty over what collected data may reveal in the future, two main approaches have been developed to eliminate the need for consent: by relying upon altruism (Choudhury et al., 2014), or solidarity-based approach instead of autonomy-based consent approaches (Prainsack & Buyx, 2013).",Data protection,data,https://w3id.org/dpv#Data
0,118,"Given the extensive uncertainty over what collected data may reveal in the future, two main approaches have been developed to eliminate the need for consent: by relying upon altruism (Choudhury et al., 2014), or solidarity-based approach instead of autonomy-based consent approaches (Prainsack & Buyx, 2013).",Data protection,consent,https://w3id.org/dpv#Consent
0,118,"According to the first approach, the data subjects who are “information altruists” with respect to their biomedical data are asked to share their data for any and all research purposes (Choudhury et al., 2014, p. 7).",Data protection,data,https://w3id.org/dpv#Data
0,118,"According to the first approach, the data subjects who are “information altruists” with respect to their biomedical data are asked to share their data for any and all research purposes (Choudhury et al., 2014, p. 7).",Data protection,data,https://w3id.org/dpv#Data
0,118,Solidarity-based approach reflects that data subjects are willing to share data or assist others in supporting research and innovation.,Data protection,data,https://w3id.org/dpv#Data
0,118,Solidarity-based approach reflects that data subjects are willing to share data or assist others in supporting research and innovation.,Data protection,share,https://w3id.org/dpv#Share
0,118,"Unlike the autonomy-based consent approaches, this approach provides data subjects with a ‘mission statement’, information about the research questions and contexts, the potential commercial value of the data, future uses, feedback procedures and risks and benefits, so as to establish   ‘‘contractual’’ rather than consent basis for the research relationship (Prainsack and Buyx 2013, pp.",Data protection,consent,https://w3id.org/dpv#Consent
0,118,"Unlike the autonomy-based consent approaches, this approach provides data subjects with a ‘mission statement’, information about the research questions and contexts, the potential commercial value of the data, future uses, feedback procedures and risks and benefits, so as to establish   ‘‘contractual’’ rather than consent basis for the research relationship (Prainsack and Buyx 2013, pp.",Data protection,data,https://w3id.org/dpv#Data
0,118,"Unlike the autonomy-based consent approaches, this approach provides data subjects with a ‘mission statement’, information about the research questions and contexts, the potential commercial value of the data, future uses, feedback procedures and risks and benefits, so as to establish   ‘‘contractual’’ rather than consent basis for the research relationship (Prainsack and Buyx 2013, pp.",Data protection,data,https://w3id.org/dpv#Data
0,118,"Unlike the autonomy-based consent approaches, this approach provides data subjects with a ‘mission statement’, information about the research questions and contexts, the potential commercial value of the data, future uses, feedback procedures and risks and benefits, so as to establish   ‘‘contractual’’ rather than consent basis for the research relationship (Prainsack and Buyx 2013, pp.",Data protection,contractual,https://w3id.org/dpv#Contractual
0,118,"According to these approaches, individuals give up their rights to consent because they are responsible for their society; or because they trust the governance bodies wherein data is shared only between ‘trusted’ bodies (Hansson, 2009, p. 9).",Data protection,consent,https://w3id.org/dpv#Consent
0,118,"According to these approaches, individuals give up their rights to consent because they are responsible for their society; or because they trust the governance bodies wherein data is shared only between ‘trusted’ bodies (Hansson, 2009, p. 9).",Data protection,data,https://w3id.org/dpv#Data
0,121,"Data ‘owners’ may restrict the redistribution and modification of data to maintain data integrity, while data ‘analysts’ are allowed to analyse data and develop intellectual property.",Ethics,property,http://eaontology.linkeddata.es/def/Property
0,121,"At the same time, data ‘owners’ may also benefit from intellectual property and innovations developed from its analysis.",Ethics,property,http://eaontology.linkeddata.es/def/Property
0,121,"To understand this issue, it is important to distinguish between two forms of ownership, as a right to ‘control’ data with regard to the redistribution and modification of data, and as a right to ‘benefit from’ data and innovations developed from analysis.",Data protection,right,https://w3id.org/dpv#Right
0,121,"To understand this issue, it is important to distinguish between two forms of ownership, as a right to ‘control’ data with regard to the redistribution and modification of data, and as a right to ‘benefit from’ data and innovations developed from analysis.",Data protection,data,https://w3id.org/dpv#Data
0,121,"To understand this issue, it is important to distinguish between two forms of ownership, as a right to ‘control’ data with regard to the redistribution and modification of data, and as a right to ‘benefit from’ data and innovations developed from analysis.",Data protection,data,https://w3id.org/dpv#Data
0,121,"Data ‘owners’ may restrict the redistribution and modification of data to maintain data integrity, while data ‘analysts’ are allowed to analyse data and develop intellectual property.",Data protection,data,https://w3id.org/dpv#Data
0,121,"Data ‘owners’ may restrict the redistribution and modification of data to maintain data integrity, while data ‘analysts’ are allowed to analyse data and develop intellectual property.",Data protection,restrict,https://w3id.org/dpv#Restrict
0,121,"Data ‘owners’ may restrict the redistribution and modification of data to maintain data integrity, while data ‘analysts’ are allowed to analyse data and develop intellectual property.",Data protection,data,https://w3id.org/dpv#Data
0,121,"Data ‘owners’ may restrict the redistribution and modification of data to maintain data integrity, while data ‘analysts’ are allowed to analyse data and develop intellectual property.",Data protection,data,https://w3id.org/dpv#Data
0,121,"At the same time, data ‘owners’ may also benefit from intellectual property and innovations developed from its analysis.",Data protection,data,https://w3id.org/dpv#Data
0,121,"At the same time, data ‘owners’ may also benefit from intellectual property and innovations developed from its analysis.",Data protection,benefit,https://w3id.org/dpv#Benefit
0,122,"Such permissibility raises ethical issues with regard to ‘human dignity’ in that permissibility facilitates commodification of individuals, allowing them to sell their body or data describing their body (Steinsbekk et al., 2013).",Ethics,human dignity,http://eaontology.linkeddata.es/def/HumanDignity
0,122,"Understanding ownership in terms of ‘control’ empowers data subjects to track and check the manipulation of their data, which can help “the existence of ‘secret’ databases and leverage societal pressure to constrain any unacceptable uses” (Tene & Polonetsky, 2013, p. 242).",Data protection,data,https://w3id.org/dpv#Data
0,122,"Understanding ownership in terms of ‘control’ empowers data subjects to track and check the manipulation of their data, which can help “the existence of ‘secret’ databases and leverage societal pressure to constrain any unacceptable uses” (Tene & Polonetsky, 2013, p. 242).",Data protection,data,https://w3id.org/dpv#Data
0,122,"Data subjects’ control can be considered as the permissibility of using research data for secondary purposes, commercial pursuits, for instance.",Data protection,data,https://w3id.org/dpv#Data
0,122,"Data subjects’ control can be considered as the permissibility of using research data for secondary purposes, commercial pursuits, for instance.",Data protection,data,https://w3id.org/dpv#Data
0,122,"Such permissibility raises ethical issues with regard to ‘human dignity’ in that permissibility facilitates commodification of individuals, allowing them to sell their body or data describing their body (Steinsbekk et al., 2013).",Data protection,data,https://w3id.org/dpv#Data
0,124,"Understanding ownership in terms of ‘benefit from’ can also enable data subjects to benefit from the data they produce and to utilise big data analytics for personal uses by being offered “meaningful rights to access their data in a usable, machine-readable format” (Tene & Polonetsky, 2013, p. 242).",Data protection,benefit,https://w3id.org/dpv#Benefit
0,126,"However, the accessibility required in both forms of ownership is associated with risks and limitations.",Data protection,required,https://w3id.org/dpv#Required
0,126,Unrestricted access to raw data may be practically useless or open to misinterpretation without data analysts’ explanations about the significance of data.,Data protection,data,https://w3id.org/dpv#Data
0,126,Unrestricted access to raw data may be practically useless or open to misinterpretation without data analysts’ explanations about the significance of data.,Data protection,data,https://w3id.org/dpv#Data
0,126,"Furthermore, data subjects may modify or manipulate their data without understanding the accuracy of their data interpretations or the completeness of the data representations.",Data protection,data,https://w3id.org/dpv#Data
0,126,"Furthermore, data subjects may modify or manipulate their data without understanding the accuracy of their data interpretations or the completeness of the data representations.",Data protection,data,https://w3id.org/dpv#Data
0,129,"argue that data subjects’ “trust is a complicated concept with regard to the confidence, belief, and expectation on the reliability, integrity, security, dependability, ability, and other characters of an entity” (Yan et al., 2014, p. 120).",Data protection,data,https://w3id.org/dpv#Data
0,129,"argue that data subjects’ “trust is a complicated concept with regard to the confidence, belief, and expectation on the reliability, integrity, security, dependability, ability, and other characters of an entity” (Yan et al., 2014, p. 120).",Data protection,entity,https://w3id.org/dpv#Entity
0,131,"Weber and Weber argue that transparency plays an essential role in increasing data subjects’ trust and suggest several steps to increase transparency: “Provide information about the intended collection, storage and/ or data processing; provide an overview of what personal data have been disclosed to what data controller under which policies; provides online access to the personal data and how they have been processed; and provide counter profiling capabilities helping the user to anticipate how their data match relevant group profiles, which may affect future opportunities or risks.” (Weber & Weber, 2010, p. 39).",AI Act,user,http://tair.adaptcentre.ie/ontologies/tair/User
0,131,"Weber and Weber argue that transparency plays an essential role in increasing data subjects’ trust and suggest several steps to increase transparency: “Provide information about the intended collection, storage and/ or data processing; provide an overview of what personal data have been disclosed to what data controller under which policies; provides online access to the personal data and how they have been processed; and provide counter profiling capabilities helping the user to anticipate how their data match relevant group profiles, which may affect future opportunities or risks.” (Weber & Weber, 2010, p. 39).",Risk,group,http://www.w3id.org/vair#Group
0,131,"Weber and Weber argue that transparency plays an essential role in increasing data subjects’ trust and suggest several steps to increase transparency: “Provide information about the intended collection, storage and/ or data processing; provide an overview of what personal data have been disclosed to what data controller under which policies; provides online access to the personal data and how they have been processed; and provide counter profiling capabilities helping the user to anticipate how their data match relevant group profiles, which may affect future opportunities or risks.” (Weber & Weber, 2010, p. 39).",Data protection,user,https://w3id.org/dpv#User
0,131,"Weber and Weber argue that transparency plays an essential role in increasing data subjects’ trust and suggest several steps to increase transparency: “Provide information about the intended collection, storage and/ or data processing; provide an overview of what personal data have been disclosed to what data controller under which policies; provides online access to the personal data and how they have been processed; and provide counter profiling capabilities helping the user to anticipate how their data match relevant group profiles, which may affect future opportunities or risks.” (Weber & Weber, 2010, p. 39).",Data protection,match,https://w3id.org/dpv#Match
0,133,Data subjects should be made aware of the possible risks and consequences of processing and analysing their data to enhance transparency and trust.,Data protection,processing,https://w3id.org/dpv#Processing
0,136,"Several regulations are defined in the GDPR to minimise privacy issues, prevent discrimination,  enhance transparency and trust, and also provide rights for data subjects.",Ethics,privacy,http://eaontology.linkeddata.es/def/Privacy
0,136,The study will examine the extent to which the GDPR can help to alleviate the identified issues and associated harms arising from the use of machine learning in healthcare.,Data protection,use,https://w3id.org/dpv#Use
0,137,"Privacy issues can be minimised by privacy by design or privacy by default; providing rights to object can prevent profiling or discrimination; transparency and awareness of the possible risks and consequences can be protected, which in turn enables data subjects to make an informed decision.",Ethics,privacy,http://eaontology.linkeddata.es/def/Privacy
0,137,"Privacy issues can be minimised by privacy by design or privacy by default; providing rights to object can prevent profiling or discrimination; transparency and awareness of the possible risks and consequences can be protected, which in turn enables data subjects to make an informed decision.",Ethics,privacy,http://eaontology.linkeddata.es/def/Privacy
0,137,"However, group rights to privacy which deals with discrimination against groups, are not considered in the GDPR.",Ethics,privacy,http://eaontology.linkeddata.es/def/Privacy
0,137,"However, group rights to privacy which deals with discrimination against groups, are not considered in the GDPR.",Risk,group,http://www.w3id.org/vair#Group
0,137,"Privacy issues can be minimised by privacy by design or privacy by default; providing rights to object can prevent profiling or discrimination; transparency and awareness of the possible risks and consequences can be protected, which in turn enables data subjects to make an informed decision.",Data protection,privacy by design,https://w3id.org/dpv#PrivacyByDesign
0,137,"Privacy issues can be minimised by privacy by design or privacy by default; providing rights to object can prevent profiling or discrimination; transparency and awareness of the possible risks and consequences can be protected, which in turn enables data subjects to make an informed decision.",Data protection,profiling,https://w3id.org/dpv#Profiling
0,139,5.9	Data Protection by Design and by Default,Data protection,data,https://w3id.org/dpv#Data
0,140,"In relation to privacy protection,  Article 25 of the GDPR creates a general duty for data controllers to implement privacy by default and privacy by design mechanisms.",Ethics,privacy,http://eaontology.linkeddata.es/def/Privacy
0,140,"In relation to privacy protection,  Article 25 of the GDPR creates a general duty for data controllers to implement privacy by default and privacy by design mechanisms.",Ethics,privacy,http://eaontology.linkeddata.es/def/Privacy
0,140,"In relation to privacy protection,  Article 25 of the GDPR creates a general duty for data controllers to implement privacy by default and privacy by design mechanisms.",Ethics,privacy,http://eaontology.linkeddata.es/def/Privacy
0,140,"In relation to privacy protection,  Article 25 of the GDPR creates a general duty for data controllers to implement privacy by default and privacy by design mechanisms.",Data protection,data,https://w3id.org/dpv#Data
0,140,"In relation to privacy protection,  Article 25 of the GDPR creates a general duty for data controllers to implement privacy by default and privacy by design mechanisms.",Data protection,privacy by design,https://w3id.org/dpv#PrivacyByDesign
0,140,"This article states that data controllers need to take into account “the state of the art, the cost of implementation and the nature, scope, context, and purposes of processing as well as the risks of varying likelihood and severity for rights and freedoms of natural persons” when personal data are processed.",Data protection,scope,https://w3id.org/dpv#Scope
0,140,"This article states that data controllers need to take into account “the state of the art, the cost of implementation and the nature, scope, context, and purposes of processing as well as the risks of varying likelihood and severity for rights and freedoms of natural persons” when personal data are processed.",Data protection,context,https://w3id.org/dpv#Context
0,140,"This article states that data controllers need to take into account “the state of the art, the cost of implementation and the nature, scope, context, and purposes of processing as well as the risks of varying likelihood and severity for rights and freedoms of natural persons” when personal data are processed.",Data protection,processing,https://w3id.org/dpv#Processing
0,140,"General principles (reflected in Article 5) must also govern technical and organisational measures, such as data minimisation, storage, and purpose limitations.",Data protection,data,https://w3id.org/dpv#Data
0,140,"General principles (reflected in Article 5) must also govern technical and organisational measures, such as data minimisation, storage, and purpose limitations.",Data protection,purpose,https://w3id.org/dpv#Purpose
0,142,"According to Article 5 (1) (c), the minimum amount of personal data should be adequate and relevant and need to fulfil the purposes for which they are processed (data minimisation).",Data protection,data,https://w3id.org/dpv#Data
0,142,"Personal data need to be processed in a manner that is compatible with explicit and legitimate purposes, and further processing for archiving, research or statistical purposes should be compatible with the initial purposes (purpose limitation, Article 5(1) (b)).",Data protection,processing,https://w3id.org/dpv#Processing
0,142,"Personal data need to be processed in a manner that is compatible with explicit and legitimate purposes, and further processing for archiving, research or statistical purposes should be compatible with the initial purposes (purpose limitation, Article 5(1) (b)).",Data protection,purpose,https://w3id.org/dpv#Purpose
0,144,"The vast data collection and sharing required to improve the accuracy of a learning model in machine learning suggest data minimalism will be unlikely or at least require a significant trade-off in terms of accuracy (Erlich et al., 2014).",Data protection,data,https://w3id.org/dpv#Data
0,144,"Data controllers may also need to consider designing machine learning algorithms that, by default, requires as little data as possible to operate because of storage and limitless re-purposing of collected data conflict with the GDPR’s guiding principles.",Data protection,data,https://w3id.org/dpv#Data
0,144,"Data controllers may also need to consider designing machine learning algorithms that, by default, requires as little data as possible to operate because of storage and limitless re-purposing of collected data conflict with the GDPR’s guiding principles.",Data protection,data,https://w3id.org/dpv#Data
0,146,5.9.1	Right to Object and Automated Individual Decision-Making,Ethics,right,http://eaontology.linkeddata.es/def/Right
0,146,5.9.1	Right to Object and Automated Individual Decision-Making,Data protection,right,https://w3id.org/dpv#Right
0,147,"Profiling and discrimination concerns are reflected in the GDPR, especially in Article 21 (right to object) and Article 22 (automated individual decision-making, including profiling).",Ethics,right,http://eaontology.linkeddata.es/def/Right
0,147,"Article 21 introduces the right of data subjects to object to personal data processing, including profiling, at any time.",Ethics,right,http://eaontology.linkeddata.es/def/Right
0,147,"If the purpose of data processing is direct marketing, the data subject will have an absolute right to object.",Ethics,right,http://eaontology.linkeddata.es/def/Right
0,147,"Profiling and discrimination concerns are reflected in the GDPR, especially in Article 21 (right to object) and Article 22 (automated individual decision-making, including profiling).",Data protection,profiling,https://w3id.org/dpv#Profiling
0,147,"Profiling and discrimination concerns are reflected in the GDPR, especially in Article 21 (right to object) and Article 22 (automated individual decision-making, including profiling).",Data protection,right,https://w3id.org/dpv#Right
0,147,"Profiling and discrimination concerns are reflected in the GDPR, especially in Article 21 (right to object) and Article 22 (automated individual decision-making, including profiling).",Data protection,profiling,https://w3id.org/dpv#Profiling
0,147,"If the purpose of data processing is direct marketing, the data subject will have an absolute right to object.",Data protection,data subject,https://w3id.org/dpv#DataSubject
0,147,"If the purpose of data processing is direct marketing, the data subject will have an absolute right to object.",Data protection,right,https://w3id.org/dpv#Right
0,147,"In all other cases, data processing must stop, unless the data controller demonstrates compelling legitimate interests for the processing that override the interests of the data subjects.",Data protection,data,https://w3id.org/dpv#Data
0,147,"In all other cases, data processing must stop, unless the data controller demonstrates compelling legitimate interests for the processing that override the interests of the data subjects.",Data protection,processing,https://w3id.org/dpv#Processing
0,147,"In all other cases, data processing must stop, unless the data controller demonstrates compelling legitimate interests for the processing that override the interests of the data subjects.",Data protection,processing,https://w3id.org/dpv#Processing
0,147,"Firstly, the compelling interests of data controllers are not defined in the framework, leaving both data controllers and data subjects uncertain (Martini, 2017).",Data protection,data,https://w3id.org/dpv#Data
0,147,"Secondly, the technical feasibility of ceasing data collection is also challenging.",Data protection,data,https://w3id.org/dpv#Data
0,147,"How data controllers can handle objections beyond ceasing all service provision remains unclear (Wachter, 2018).",Data protection,data,https://w3id.org/dpv#Data
0,149,"Furthermore, Article 22 introduces safeguards against automated decision-making, including profiling, but only when data processing is solely automated and has legal or similarly significant effects.",Data protection,profiling,https://w3id.org/dpv#Profiling
0,149,"Correspondingly, the scope of data protection law needs to be defined to offer a very promising approach for data subjects to maintain control over how the data is used to personalise services and future opportunities.",Data protection,data,https://w3id.org/dpv#Data
0,149,"Correspondingly, the scope of data protection law needs to be defined to offer a very promising approach for data subjects to maintain control over how the data is used to personalise services and future opportunities.",Data protection,data,https://w3id.org/dpv#Data
0,151,"Articles 12-23 introduce rights of the data subjects, including transparency and modalities, information and access to personal data, rectification and erasure, right to object and automated individual decision-making, and restrictions.",Ethics,right,http://eaontology.linkeddata.es/def/Right
0,151,"According to this article, the risks concerning discrimination and privacy will be mitigated or reduced if the impacts of data processing on personal data protection are identified and measured.",Ethics,privacy,http://eaontology.linkeddata.es/def/Privacy
0,151,"On the one hand, the identification of privacy risks is a crucial part of DPIA.",Ethics,privacy,http://eaontology.linkeddata.es/def/Privacy
0,151,"As a result, I argue that DPIA can help to mitigate privacy risks, but DPIA cannot address discrimination risks.",Ethics,privacy,http://eaontology.linkeddata.es/def/Privacy
0,151,"Notably, Article 35 (data protection impact assessment) can also help to mitigate risks.",Data protection,article 35,https://w3id.org/dpv#Article35
0,151,"Articles 12-23 introduce rights of the data subjects, including transparency and modalities, information and access to personal data, rectification and erasure, right to object and automated individual decision-making, and restrictions.",Data protection,right,https://w3id.org/dpv#Right
0,151,"The risk to the rights of data subjects may result from personal data processing that could lead to discrimination, or a loss of control over their personal information (Recital 75).",Data protection,risk,https://w3id.org/dpv#Risk
0,151,"On the other hand, investigation to what extent processing of information affects personal data protection may reduce discrimination.",Data protection,processing,https://w3id.org/dpv#Processing
0,151,"Even though personal data are protected in machine learning, discrimination risks may also be caused by inferences and algorithms used in ML.",Data protection,data,https://w3id.org/dpv#Data
0,154,"According to  Article 7(2), a request for consent needs to be “in an intelligible and easily accessible form, using clear and plain consent.” Article 12(7) explains that “the information to be provided to data subjects pursuant to Articles 13 and 14 may be provided in combination with standardise icons in order to give in an easily visible, intelligible, and clearly legible manner a meaningful overview of the intended processing.” New frameworks thus prefer short text with icons over long privacy statements.",Ethics,privacy,http://eaontology.linkeddata.es/def/Privacy
0,154,Articles 13 and 14 aim to make data subjects aware of the intended data collection without expecting them to read elaborate privacy notices.,Ethics,privacy,http://eaontology.linkeddata.es/def/Privacy
0,154,Articles 13 and 14 aim to make data subjects aware of the intended data collection without expecting them to read elaborate privacy notices.,AI Act,intended data,http://tair.adaptcentre.ie/ontologies/tair/IntendedData
0,154,"In relation to informed consent, Articles 7 has been developed, which explains the conditions for consent.",Data protection,consent,https://w3id.org/dpv#Consent
0,154,"According to  Article 7(2), a request for consent needs to be “in an intelligible and easily accessible form, using clear and plain consent.” Article 12(7) explains that “the information to be provided to data subjects pursuant to Articles 13 and 14 may be provided in combination with standardise icons in order to give in an easily visible, intelligible, and clearly legible manner a meaningful overview of the intended processing.” New frameworks thus prefer short text with icons over long privacy statements.",Data protection,consent,https://w3id.org/dpv#Consent
0,154,"According to  Article 7(2), a request for consent needs to be “in an intelligible and easily accessible form, using clear and plain consent.” Article 12(7) explains that “the information to be provided to data subjects pursuant to Articles 13 and 14 may be provided in combination with standardise icons in order to give in an easily visible, intelligible, and clearly legible manner a meaningful overview of the intended processing.” New frameworks thus prefer short text with icons over long privacy statements.",Data protection,consent,https://w3id.org/dpv#Consent
0,154,"According to  Article 7(2), a request for consent needs to be “in an intelligible and easily accessible form, using clear and plain consent.” Article 12(7) explains that “the information to be provided to data subjects pursuant to Articles 13 and 14 may be provided in combination with standardise icons in order to give in an easily visible, intelligible, and clearly legible manner a meaningful overview of the intended processing.” New frameworks thus prefer short text with icons over long privacy statements.",Data protection,processing,https://w3id.org/dpv#Processing
0,154,Articles 13 and 14 aim to make data subjects aware of the intended data collection without expecting them to read elaborate privacy notices.,Data protection,data,https://w3id.org/dpv#Data
0,154,"In recognition of the unforeseen inferences drawn from data analytics, the possible risks of machine learning might not be anticipated or anticipatable, meaning that achieving the goal with notification alone remains uncertain (Wachter, 2018).",Data protection,data,https://w3id.org/dpv#Data
0,157,"Article 4(1) of the GDPR defines ‘personal data’ as “any information relating to an identified or identifiable natural person (‘data subject’),” whereas an ‘identifiable natural person’ is defined as “one who can be identified, directly or indirectly, in particular by reference to an identifier such as name, an identification number, location data, an online identifier or o one or more factors specific to the physical, physiological, genetic, mental, economic, cultural or social identity of that natural person.”",Risk,natural person,http://www.w3id.org/vair#NaturalPerson
0,157,"Article 4(1) of the GDPR defines ‘personal data’ as “any information relating to an identified or identifiable natural person (‘data subject’),” whereas an ‘identifiable natural person’ is defined as “one who can be identified, directly or indirectly, in particular by reference to an identifier such as name, an identification number, location data, an online identifier or o one or more factors specific to the physical, physiological, genetic, mental, economic, cultural or social identity of that natural person.”",Data protection,data,https://w3id.org/dpv#Data
0,157,"Article 4(1) of the GDPR defines ‘personal data’ as “any information relating to an identified or identifiable natural person (‘data subject’),” whereas an ‘identifiable natural person’ is defined as “one who can be identified, directly or indirectly, in particular by reference to an identifier such as name, an identification number, location data, an online identifier or o one or more factors specific to the physical, physiological, genetic, mental, economic, cultural or social identity of that natural person.”",Data protection,natural person,https://w3id.org/dpv#NaturalPerson
0,157,"Article 4(1) of the GDPR defines ‘personal data’ as “any information relating to an identified or identifiable natural person (‘data subject’),” whereas an ‘identifiable natural person’ is defined as “one who can be identified, directly or indirectly, in particular by reference to an identifier such as name, an identification number, location data, an online identifier or o one or more factors specific to the physical, physiological, genetic, mental, economic, cultural or social identity of that natural person.”",Data protection,data,https://w3id.org/dpv#Data
0,157,"Article 4(1) of the GDPR defines ‘personal data’ as “any information relating to an identified or identifiable natural person (‘data subject’),” whereas an ‘identifiable natural person’ is defined as “one who can be identified, directly or indirectly, in particular by reference to an identifier such as name, an identification number, location data, an online identifier or o one or more factors specific to the physical, physiological, genetic, mental, economic, cultural or social identity of that natural person.”",Data protection,natural person,https://w3id.org/dpv#NaturalPerson
0,157,"Article 4(1) of the GDPR defines ‘personal data’ as “any information relating to an identified or identifiable natural person (‘data subject’),” whereas an ‘identifiable natural person’ is defined as “one who can be identified, directly or indirectly, in particular by reference to an identifier such as name, an identification number, location data, an online identifier or o one or more factors specific to the physical, physiological, genetic, mental, economic, cultural or social identity of that natural person.”",Data protection,location,https://w3id.org/dpv#Location
0,159,"Malgieri (2016) highlights the fact that the GDPR “recognizes different levels of control rights to consumers in accordance with a ‘proprietarian’ approach to personal data.” (Malgieri, 2016, p. 133).",Data protection,personal data,https://w3id.org/dpv#PersonalData
0,159,"It seems that the GDPR has increased the control individuals have over the collection, processing, and sharing of their personal data, and created a certain impression of personal data ownership (Howard, 2012).",Data protection,processing,https://w3id.org/dpv#Processing
0,159,"(2019) argue that although the GDPR grants rights to data subjects, it does not regulate the question of data ownership.",Data protection,data,https://w3id.org/dpv#Data
0,159,"(2019) argue that although the GDPR grants rights to data subjects, it does not regulate the question of data ownership.",Data protection,data,https://w3id.org/dpv#Data
0,159,"Therefore, GDPR does not recognise a property right of individuals in their data.",Data protection,right,https://w3id.org/dpv#Right
0,159,"Therefore, GDPR does not recognise a property right of individuals in their data.",Data protection,data,https://w3id.org/dpv#Data
0,162,"These provisions suggest that privacy, data protection, and security contribute to increasing transparency and trust between data subjects and controllers.",Ethics,privacy,http://eaontology.linkeddata.es/def/Privacy
0,162,"In the case of a personal data breach, controllers must inform the supervisory authority within 72 hours.",Risk,authority,http://www.w3id.org/vair#Authority
0,162,"Secondly, Article (33) describes how data controllers must react to data breaches.",Data protection,data,https://w3id.org/dpv#Data
0,162,"In the case of a personal data breach, controllers must inform the supervisory authority within 72 hours.",Data protection,data,https://w3id.org/dpv#Data
0,162,"In the case of a personal data breach, controllers must inform the supervisory authority within 72 hours.",Data protection,authority,https://w3id.org/dpv#Authority
0,162,"These provisions suggest that privacy, data protection, and security contribute to increasing transparency and trust between data subjects and controllers.",Data protection,data,https://w3id.org/dpv#Data
0,163,5.9.5	Inferential Privacy: Group Right to Privacy,Risk,group,http://www.w3id.org/vair#Group
0,163,5.9.5	Inferential Privacy: Group Right to Privacy,Data protection,right,https://w3id.org/dpv#Right
0,164,The field related to the privacy implications of production and the use of inferred data may be called ‘inferential privacy’.,Ethics,privacy,http://eaontology.linkeddata.es/def/Privacy
0,164,The field related to the privacy implications of production and the use of inferred data may be called ‘inferential privacy’.,Ethics,privacy,http://eaontology.linkeddata.es/def/Privacy
0,164,"Inferential privacy deals with the inferences that can be made about a group of people defined by a feature shared by all individuals in the group (O'Callaghan, 2018).",Ethics,privacy,http://eaontology.linkeddata.es/def/Privacy
0,164,"Inferential privacy deals with the inferences that can be made about a group of people defined by a feature shared by all individuals in the group (O'Callaghan, 2018).",Risk,group,http://www.w3id.org/vair#Group
0,164,"Inferential privacy deals with the inferences that can be made about a group of people defined by a feature shared by all individuals in the group (O'Callaghan, 2018).",Risk,group,http://www.w3id.org/vair#Group
0,164,"However, in an era of machine learning where analytics are being developed to operate at a broad scale, the individual is often incidental to the analysis.",Data protection,scale,https://w3id.org/dpv#Scale
0,166,"Thus, it is important to assign a right to a group as an autonomous entity, not as a collection of individuals, in order to support that group against discriminative harms (Taylor et al., 2017).",Ethics,right,http://eaontology.linkeddata.es/def/Right
0,166,Granting this right to groups is different from the already existing right in the field of privacy and data protection in that this right to privacy is not reducible to the privacy of the individuals forming such groups.,Ethics,right,http://eaontology.linkeddata.es/def/Right
0,166,Granting this right to groups is different from the already existing right in the field of privacy and data protection in that this right to privacy is not reducible to the privacy of the individuals forming such groups.,Ethics,right,http://eaontology.linkeddata.es/def/Right
0,166,Granting this right to groups is different from the already existing right in the field of privacy and data protection in that this right to privacy is not reducible to the privacy of the individuals forming such groups.,Ethics,privacy,http://eaontology.linkeddata.es/def/Privacy
0,166,Granting this right to groups is different from the already existing right in the field of privacy and data protection in that this right to privacy is not reducible to the privacy of the individuals forming such groups.,Ethics,privacy,http://eaontology.linkeddata.es/def/Privacy
0,166,Granting this right to groups is different from the already existing right in the field of privacy and data protection in that this right to privacy is not reducible to the privacy of the individuals forming such groups.,Ethics,privacy,http://eaontology.linkeddata.es/def/Privacy
0,166,That is a reason as to why a right to group inferential privacy is not reducible to individual inferential privacy.,Ethics,right,http://eaontology.linkeddata.es/def/Right
0,166,That is a reason as to why a right to group inferential privacy is not reducible to individual inferential privacy.,Ethics,privacy,http://eaontology.linkeddata.es/def/Privacy
0,166,That is a reason as to why a right to group inferential privacy is not reducible to individual inferential privacy.,Ethics,privacy,http://eaontology.linkeddata.es/def/Privacy
0,166,"By interpreting inferential privacy as a right limiting the potential harms that can derive from invasive and discriminatory data processing, privacy can address the issues that revolve around the risks of discrimination and the adverse outcomes of the massive analysis of data.",Ethics,privacy,http://eaontology.linkeddata.es/def/Privacy
0,166,"Since the group is exposed to the risks deriving from the creation and use of inferred data, it is important to protect groups against inferential data.",Risk,group,http://www.w3id.org/vair#Group
0,166,"Thus, it is important to assign a right to a group as an autonomous entity, not as a collection of individuals, in order to support that group against discriminative harms (Taylor et al., 2017).",Risk,group,http://www.w3id.org/vair#Group
0,166,"Thus, it is important to assign a right to a group as an autonomous entity, not as a collection of individuals, in order to support that group against discriminative harms (Taylor et al., 2017).",Risk,group,http://www.w3id.org/vair#Group
0,166,"The training set may not contain all the members of the group (e.g., people of the same origin), meaning that although there is no loss in individual inferential privacy (because members of the training set gave full informed consent to the collection, analysis and inference of the data), there is a loss to the broader group, i.e.",Risk,group,http://www.w3id.org/vair#Group
0,166,"The training set may not contain all the members of the group (e.g., people of the same origin), meaning that although there is no loss in individual inferential privacy (because members of the training set gave full informed consent to the collection, analysis and inference of the data), there is a loss to the broader group, i.e.",Risk,group,http://www.w3id.org/vair#Group
0,166,That is a reason as to why a right to group inferential privacy is not reducible to individual inferential privacy.,Risk,group,http://www.w3id.org/vair#Group
0,166,"Since the group is exposed to the risks deriving from the creation and use of inferred data, it is important to protect groups against inferential data.",Data protection,data,https://w3id.org/dpv#Data
0,166,"Thus, it is important to assign a right to a group as an autonomous entity, not as a collection of individuals, in order to support that group against discriminative harms (Taylor et al., 2017).",Data protection,right,https://w3id.org/dpv#Right
0,166,"Thus, it is important to assign a right to a group as an autonomous entity, not as a collection of individuals, in order to support that group against discriminative harms (Taylor et al., 2017).",Data protection,entity,https://w3id.org/dpv#Entity
0,166,Granting this right to groups is different from the already existing right in the field of privacy and data protection in that this right to privacy is not reducible to the privacy of the individuals forming such groups.,Data protection,right,https://w3id.org/dpv#Right
0,166,Granting this right to groups is different from the already existing right in the field of privacy and data protection in that this right to privacy is not reducible to the privacy of the individuals forming such groups.,Data protection,right,https://w3id.org/dpv#Right
0,166,Granting this right to groups is different from the already existing right in the field of privacy and data protection in that this right to privacy is not reducible to the privacy of the individuals forming such groups.,Data protection,right,https://w3id.org/dpv#Right
0,166,"The training set may not contain all the members of the group (e.g., people of the same origin), meaning that although there is no loss in individual inferential privacy (because members of the training set gave full informed consent to the collection, analysis and inference of the data), there is a loss to the broader group, i.e.",Data protection,data,https://w3id.org/dpv#Data
0,166,That is a reason as to why a right to group inferential privacy is not reducible to individual inferential privacy.,Data protection,right,https://w3id.org/dpv#Right
0,166,"By interpreting inferential privacy as a right limiting the potential harms that can derive from invasive and discriminatory data processing, privacy can address the issues that revolve around the risks of discrimination and the adverse outcomes of the massive analysis of data.",Data protection,right,https://w3id.org/dpv#Right
0,166,"By interpreting inferential privacy as a right limiting the potential harms that can derive from invasive and discriminatory data processing, privacy can address the issues that revolve around the risks of discrimination and the adverse outcomes of the massive analysis of data.",Data protection,derive,https://w3id.org/dpv#Derive
0,166,"By interpreting inferential privacy as a right limiting the potential harms that can derive from invasive and discriminatory data processing, privacy can address the issues that revolve around the risks of discrimination and the adverse outcomes of the massive analysis of data.",Data protection,data,https://w3id.org/dpv#Data
0,168,"Therefore, I argue that the concept of a right to inferential group privacy is important in relation to machine learning because it deals with the inferences that can be made about groups.",Ethics,right,http://eaontology.linkeddata.es/def/Right
0,168,"Therefore, I argue that the concept of a right to inferential group privacy is important in relation to machine learning because it deals with the inferences that can be made about groups.",Ethics,privacy,http://eaontology.linkeddata.es/def/Privacy
0,168,"Consequently, the enhancement of inferential privacy-preserving strategies mitigates or reduces the likelihood of inequality and discriminatory practices against groups in machine learning.",Ethics,privacy,http://eaontology.linkeddata.es/def/Privacy
0,168,"Therefore, I argue that the concept of a right to inferential group privacy is important in relation to machine learning because it deals with the inferences that can be made about groups.",Risk,group,http://www.w3id.org/vair#Group
0,168,"Therefore, I argue that the concept of a right to inferential group privacy is important in relation to machine learning because it deals with the inferences that can be made about groups.",Data protection,right,https://w3id.org/dpv#Right
0,168,"Consequently, the enhancement of inferential privacy-preserving strategies mitigates or reduces the likelihood of inequality and discriminatory practices against groups in machine learning.",Data protection,likelihood,https://w3id.org/dpv#Likelihood
0,173,•	Privacy is one of the ethical issues caused by the application of ML in healthcare.,Ethics,privacy,http://eaontology.linkeddata.es/def/Privacy
0,174,"The descriptive notion of privacy holds that for privacy to be diminished, private information must be accessed by an individual.",Ethics,privacy,http://eaontology.linkeddata.es/def/Privacy
0,174,"The descriptive notion of privacy holds that for privacy to be diminished, private information must be accessed by an individual.",Ethics,privacy,http://eaontology.linkeddata.es/def/Privacy
0,174,"Thus, with regard to this definition, in a fully automated system, there are no privacy issues (Macnish, 2020).",Ethics,privacy,http://eaontology.linkeddata.es/def/Privacy
0,175,"The normative notion of privacy holds that any information practice that leads to a loss of or reduction in exercising control over personal information causes harm to privacy (Moore, 2003).",Ethics,privacy,http://eaontology.linkeddata.es/def/Privacy
0,175,"The normative notion of privacy holds that any information practice that leads to a loss of or reduction in exercising control over personal information causes harm to privacy (Moore, 2003).",Ethics,privacy,http://eaontology.linkeddata.es/def/Privacy
0,175,"In order to identify privacy issues related to this notion of privacy, I distinguish different phases of machine learning.",Ethics,privacy,http://eaontology.linkeddata.es/def/Privacy
0,175,"The normative notion of privacy holds that any information practice that leads to a loss of or reduction in exercising control over personal information causes harm to privacy (Moore, 2003).",Data protection,harm,https://w3id.org/dpv#Harm
0,176,"Anonymisation, as a safeguard to protect privacy, faces challenges in that there is a possibility of de-anonymisation when datasets are linked or aggregated (Ohm, 2010).",Ethics,privacy,http://eaontology.linkeddata.es/def/Privacy
0,176,"Anonymisation, as a safeguard to protect privacy, faces challenges in that there is a possibility of de-anonymisation when datasets are linked or aggregated (Ohm, 2010).",Data protection,safeguard,https://w3id.org/dpv#Safeguard
0,178,Table 12 Privacy Issues in Machine Learning,Ethics,privacy,http://eaontology.linkeddata.es/def/Privacy
0,179,ML risky phases	Types of privacy issues	Causes of issues,Ethics,privacy,http://eaontology.linkeddata.es/def/Privacy
0,180,Training a model	·        Link to data subject identity,Data protection,data subject,https://w3id.org/dpv#DataSubject
0,181,"·        Revealing sensitive/ confidential/ private information	7   	Data collection, storage and share",Data protection,data,https://w3id.org/dpv#Data
0,181,"·        Revealing sensitive/ confidential/ private information	7   	Data collection, storage and share",Data protection,share,https://w3id.org/dpv#Share
0,183,9   	Combine data with other datasets,Data protection,combine,https://w3id.org/dpv#Combine
0,183,9   	Combine data with other datasets,Data protection,data,https://w3id.org/dpv#Data
0,184,"Inference through a model	·        Generate information, predict, inference about data subject	10	Inferential analysis of sensitive information",Data protection,generate,https://w3id.org/dpv#Generate
0,184,"Inference through a model	·        Generate information, predict, inference about data subject	10	Inferential analysis of sensitive information",Data protection,data,https://w3id.org/dpv#Data
0,185,Releasing a model	·        Determining members of a group	11	Inference membership,Risk,group,http://www.w3id.org/vair#Group
0,188,"Data linkage or aggregation might have harmful discriminative consequences for individuals and the public (Favaretto et al., 2019).",Data protection,data,https://w3id.org/dpv#Data
0,188,"Profiling can result in discrimination against individuals through predicting their preferences and habits, or inferences their health diseases (Peppet, 2014).",Data protection,profiling,https://w3id.org/dpv#Profiling
0,188,"Furthermore, discrimination caused by technology can be perceived as a legal practice in society (de Vries, 2010).",Data protection,technology,https://w3id.org/dpv#Technology
0,189,"Inferences drawn from the data can have harmful outcomes for a clustered group of people generated or discovered by algorithms (Taylor et al., 2017).",Risk,group,http://www.w3id.org/vair#Group
0,189,"Inferences drawn from the data can have harmful outcomes for a clustered group of people generated or discovered by algorithms (Taylor et al., 2017).",Data protection,data,https://w3id.org/dpv#Data
0,190,"The various reasons related to algorithmic causes of discrimination are defining target variables, and class labels, training data, collecting data, the complexity of algorithms, and selecting features or attributes that can cause discriminatory outcomes in machine learning (Barocas & Selbst, 2016; Burrell, 2016; d’Alessandro et al., 2017; (Schermer, 2011).",AI Act,training data,http://tair.adaptcentre.ie/ontologies/tair/TrainingData
0,191,"The digital divide is ethically problematic in terms of justice (Lewis et al., 2012)",Ethics,justice,http://eaontology.linkeddata.es/def/Justice
0,191,"Digital divide caused by inequality or injustice in skills, resources, geographical location, age, income, gender, education, and race is another discriminative outcome of using machine learning (Favaretto et al., 2019).",Data protection,location,https://w3id.org/dpv#Location
0,192,•	Informed consent is another key ethical issue.,Data protection,consent,https://w3id.org/dpv#Consent
0,192,Uncertain inferences and consequences accompanying the application of machine learning create challenges for obtaining informed consent.,Data protection,consent,https://w3id.org/dpv#Consent
0,192,"However, different models of informed consent are developed, such as blanket and broad.",Data protection,consent,https://w3id.org/dpv#Consent
0,192,"But, obtaining such consent is not an easy task for controllers and raises concerns about autonomy (Boyd & Crawford, 2012; Master et al., 2015).",Data protection,consent,https://w3id.org/dpv#Consent
0,193,"One the one hand, data subjects are unable to control the flow of their information (Steinsbekk et al., 2013).",Data protection,data,https://w3id.org/dpv#Data
0,193,"On the other hand, restricted access to data makes it difficult for data subjects to benefit from the data they produce (Tene & Polonetsky, 2013, p. 242).",Data protection,data,https://w3id.org/dpv#Data
0,194,Data subjects are unaware of the function of machine learning and the inferences drawn from large datasets.,Data protection,data,https://w3id.org/dpv#Data
0,194,"Being unaware of the possible risks and consequences of processing and analysing data decreases the level of trust and transparency in machine learning (Weber & Weber, 2010).",Data protection,processing,https://w3id.org/dpv#Processing
0,194,"Being unaware of the possible risks and consequences of processing and analysing data decreases the level of trust and transparency in machine learning (Weber & Weber, 2010).",Data protection,data,https://w3id.org/dpv#Data
0,197,"However, I argue that DPIA can help to mitigate privacy risks in ML.",Ethics,privacy,http://eaontology.linkeddata.es/def/Privacy
0,197,"●	Data protection by design and by default (Article 25): data minimization, storage, and purpose limitation face implementation barriers in machine learning (Wachter, 2018).",AI Act,): data,http://tair.adaptcentre.ie/ontologies/tair/):Data
0,197,"●	Data protection by design and by default (Article 25): data minimization, storage, and purpose limitation face implementation barriers in machine learning (Wachter, 2018).",Data protection,data,https://w3id.org/dpv#Data
0,197,"●	Data protection by design and by default (Article 25): data minimization, storage, and purpose limitation face implementation barriers in machine learning (Wachter, 2018).",Data protection,data,https://w3id.org/dpv#Data
0,197,"●	Data protection by design and by default (Article 25): data minimization, storage, and purpose limitation face implementation barriers in machine learning (Wachter, 2018).",Data protection,purpose,https://w3id.org/dpv#Purpose
0,198,"●	Right to object (Article 21) and automated individual decision-making, including profiling (Article 22): Compelling interests of data controllers are not properly defined in Article 21(Martini, 2017), and safeguards introduced in Article 22 are limited with regard to the scope of applicability (Wachter et al., 2017).",Ethics,right,http://eaontology.linkeddata.es/def/Right
0,198,"●	Right to object (Article 21) and automated individual decision-making, including profiling (Article 22): Compelling interests of data controllers are not properly defined in Article 21(Martini, 2017), and safeguards introduced in Article 22 are limited with regard to the scope of applicability (Wachter et al., 2017).",Data protection,right,https://w3id.org/dpv#Right
0,198,"●	Right to object (Article 21) and automated individual decision-making, including profiling (Article 22): Compelling interests of data controllers are not properly defined in Article 21(Martini, 2017), and safeguards introduced in Article 22 are limited with regard to the scope of applicability (Wachter et al., 2017).",Data protection,data,https://w3id.org/dpv#Data
0,198,"●	Right to object (Article 21) and automated individual decision-making, including profiling (Article 22): Compelling interests of data controllers are not properly defined in Article 21(Martini, 2017), and safeguards introduced in Article 22 are limited with regard to the scope of applicability (Wachter et al., 2017).",Data protection,scope,https://w3id.org/dpv#Scope
0,199,"Thus, they cannot provide an intelligible and easily accessible form using for consent (Wachter, 2018).",Data protection,consent,https://w3id.org/dpv#Consent
0,200,"●	 Ownership (Article 4): although the GDPR grants rights to data subjects, it does not regulate the question of data ownership (Debussche et al., 2019).",Data protection,data,https://w3id.org/dpv#Data
0,200,"●	 Ownership (Article 4): although the GDPR grants rights to data subjects, it does not regulate the question of data ownership (Debussche et al., 2019).",Data protection,data,https://w3id.org/dpv#Data
0,202,"●	Group right to privacy: From my perspective, inferential privacy needs to be assigned to a group in order to protect groups against discrimination.",Risk,group,http://www.w3id.org/vair#Group
0,202,"●	Group right to privacy: From my perspective, inferential privacy needs to be assigned to a group in order to protect groups against discrimination.",Risk,group,http://www.w3id.org/vair#Group
0,202,"●	Group right to privacy: From my perspective, inferential privacy needs to be assigned to a group in order to protect groups against discrimination.",Data protection,right,https://w3id.org/dpv#Right
0,206,"The second section discussed privacy issues, discrimination and elements that cause inequality in machine learning, issues related to obtaining informed consent and different models of consent, issues related to ownership, and challenges of enhancing transparency and trust in machine learning.",Ethics,privacy,http://eaontology.linkeddata.es/def/Privacy
0,206,"The second section discussed privacy issues, discrimination and elements that cause inequality in machine learning, issues related to obtaining informed consent and different models of consent, issues related to ownership, and challenges of enhancing transparency and trust in machine learning.",Data protection,consent,https://w3id.org/dpv#Consent
0,206,"The second section discussed privacy issues, discrimination and elements that cause inequality in machine learning, issues related to obtaining informed consent and different models of consent, issues related to ownership, and challenges of enhancing transparency and trust in machine learning.",Data protection,consent,https://w3id.org/dpv#Consent
0,206,"It is important to note that these issues are not specifically caused by the application of machine learning in the healthcare area, and it is more likely that the use of machine learning in other areas causes the ethical issues identified in this study.",Data protection,use,https://w3id.org/dpv#Use
0,208,"However, these frameworks require further specification in order to cover the other ethical issues, namely informed consent, ownership, and group right to privacy, in ML.",Risk,group,http://www.w3id.org/vair#Group
0,208,"However, these frameworks require further specification in order to cover the other ethical issues, namely informed consent, ownership, and group right to privacy, in ML.",Data protection,consent,https://w3id.org/dpv#Consent
0,208,"However, these frameworks require further specification in order to cover the other ethical issues, namely informed consent, ownership, and group right to privacy, in ML.",Data protection,right,https://w3id.org/dpv#Right
